{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0c897db21ab04082bdccfd49d037bdf2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3717f7789bc40f68b813c94d3a5fc10","IPY_MODEL_7d9f5a1e3ee344978c3c0ac901aa2e1d","IPY_MODEL_8fc869d5596544868e7a59e1a34a4068"],"layout":"IPY_MODEL_803a76dd401240129f81a5ba69ba638a"}},"d3717f7789bc40f68b813c94d3a5fc10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3ba7c26bb1a4d57a23713263d72464b","placeholder":"​","style":"IPY_MODEL_83d2b8199e564f87a2549dc9ee3a40f1","value":"Map: 100%"}},"7d9f5a1e3ee344978c3c0ac901aa2e1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bd742d669df427db395b37fdb00cfa3","max":12,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90f93880a915457eb5481d634c9b44aa","value":12}},"8fc869d5596544868e7a59e1a34a4068":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d103226b44ee448db91b768d11242fa5","placeholder":"​","style":"IPY_MODEL_171b106bca8645689269ce507aa9d0d9","value":" 12/12 [00:00&lt;00:00, 235.51 examples/s]"}},"803a76dd401240129f81a5ba69ba638a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3ba7c26bb1a4d57a23713263d72464b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83d2b8199e564f87a2549dc9ee3a40f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bd742d669df427db395b37fdb00cfa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90f93880a915457eb5481d634c9b44aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d103226b44ee448db91b768d11242fa5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"171b106bca8645689269ce507aa9d0d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e0e29b805bd492e8b12eb66d5fb0aa9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d00159c68e3a41909e293fe498292ecc","IPY_MODEL_23d76f1eece04a2ba6f78c427feb085f","IPY_MODEL_817ae316c1694dfab0e3e560d322dd4f"],"layout":"IPY_MODEL_6769c745d7ca45bf87b88e2a21ad749e"}},"d00159c68e3a41909e293fe498292ecc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0f330849662421ca2e00277f8026c17","placeholder":"​","style":"IPY_MODEL_68458e7593bd4479b288b123d6efaed9","value":"Map: 100%"}},"23d76f1eece04a2ba6f78c427feb085f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_678d6c5ae0cc488da448a7c51661ff65","max":12,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0714a7eeb2f40c29d7078973148bb39","value":12}},"817ae316c1694dfab0e3e560d322dd4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de513162f0a04ccd84bf44380944aa54","placeholder":"​","style":"IPY_MODEL_45d97d41f1cd4e6e896867afdb55275b","value":" 12/12 [00:00&lt;00:00, 247.44 examples/s]"}},"6769c745d7ca45bf87b88e2a21ad749e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0f330849662421ca2e00277f8026c17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68458e7593bd4479b288b123d6efaed9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"678d6c5ae0cc488da448a7c51661ff65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0714a7eeb2f40c29d7078973148bb39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de513162f0a04ccd84bf44380944aa54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45d97d41f1cd4e6e896867afdb55275b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11165638,"sourceType":"datasetVersion","datasetId":6671304}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf","metadata":{"id":"L-GGvsTO1_p7","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:30:51.374106Z","iopub.execute_input":"2025-03-26T07:30:51.374405Z","iopub.status.idle":"2025-03-26T07:31:03.062214Z","shell.execute_reply.started":"2025-03-26T07:30:51.374381Z","shell.execute_reply":"2025-03-26T07:31:03.061531Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\nmodel_name = \"csebuetnlp/banglabert\"\nmodel = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"id":"H5B4Zk3ReXO-","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:31:03.063197Z","iopub.execute_input":"2025-03-26T07:31:03.063884Z","iopub.status.idle":"2025-03-26T07:31:15.700129Z","shell.execute_reply.started":"2025-03-26T07:31:03.063831Z","shell.execute_reply":"2025-03-26T07:31:15.699161Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/586 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d34ffd254b74bc4818586f36d1cba4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ba86780bb2d40efa1fcfba43922b89a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65a7fd67ccac4d95ba4bbdb037f139d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/528k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5720ad19735c40608733feae59b1f6c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b77c865aa44cf1b9d3d597fae1e638"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel\n\nclass BanglaBERT_LSTM(nn.Module):\n    def __init__(self, lstm_hidden_size=256, lstm_layers=1, dropout=0.3):\n        super(BanglaBERT_LSTM, self).__init__()\n\n        self.bert = model\n        self.lstm = nn.LSTM(input_size=768, hidden_size=lstm_hidden_size, num_layers=lstm_layers,\n                            batch_first=True, bidirectional=True, dropout=dropout)\n        self.fc = nn.Linear(lstm_hidden_size * 2, 1)  \n        self.dropout = nn.Dropout(dropout)\n        self.criterion = nn.BCEWithLogitsLoss()\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        # Get embeddings from BanglaBERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_states = outputs.last_hidden_state  # (batch_size, seq_len, 768)\n\n        # Pass through BiLSTM\n        lstm_out, _ = self.lstm(hidden_states)  # (batch_size, seq_len, hidden_size*2)\n        lstm_out = lstm_out[:, -1, :]  # Take the last time step output\n\n        # Pass through the classifier\n        logits = self.fc(self.dropout(lstm_out))  # (batch_size, 1)\n\n        # Compute loss if labels are provided\n        loss = None\n        if labels is not None:\n            labels = labels.float().unsqueeze(1)  \n            loss = self.criterion(logits, labels)\n\n        return (loss, logits) if loss is not None else logits","metadata":{"id":"ZIm7rqulemXR","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:31:21.168309Z","iopub.execute_input":"2025-03-26T07:31:21.169352Z","iopub.status.idle":"2025-03-26T07:31:21.176944Z","shell.execute_reply.started":"2025-03-26T07:31:21.169312Z","shell.execute_reply":"2025-03-26T07:31:21.175882Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model = BanglaBERT_LSTM()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lq4UR-wVeyqe","outputId":"10e97acb-fd0c-482f-9b2d-4623eb0ec39a","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:31:22.346111Z","iopub.execute_input":"2025-03-26T07:31:22.346395Z","iopub.status.idle":"2025-03-26T07:31:22.371937Z","shell.execute_reply.started":"2025-03-26T07:31:22.346373Z","shell.execute_reply":"2025-03-26T07:31:22.371235Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/input/unber-1k/BB-LSTM.pth\"))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vl9bl8Dye1iz","outputId":"44790700-ee4c-4d9d-82c8-26f2f923a032","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:31:24.112239Z","iopub.execute_input":"2025-03-26T07:31:24.112563Z","iopub.status.idle":"2025-03-26T07:31:29.246932Z","shell.execute_reply.started":"2025-03-26T07:31:24.112533Z","shell.execute_reply":"2025-03-26T07:31:29.243516Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-5-6e2c09698994>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/input/unber-1k/BB-LSTM.pth\"))\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model1 = AutoModel.from_pretrained(model_name, num_labels=3)","metadata":{"id":"ooQy2bwpgZc2","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:48:04.646302Z","iopub.execute_input":"2025-03-26T07:48:04.646743Z","iopub.status.idle":"2025-03-26T07:48:05.008156Z","shell.execute_reply.started":"2025-03-26T07:48:04.646684Z","shell.execute_reply":"2025-03-26T07:48:05.006848Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"class BanglaBERT_LSTM_Multiclass(nn.Module):\n    def __init__(self, lstm_hidden_size=256, lstm_layers=1, dropout=0.3, num_classes=3):\n        super(BanglaBERT_LSTM_Multiclass, self).__init__()\n\n        self.bert = model1  # Example, change to correct model\n\n        self.lstm = nn.LSTM(input_size=768, hidden_size=lstm_hidden_size, num_layers=lstm_layers,\n                            batch_first=True, bidirectional=True, dropout=dropout)\n\n        self.fc = nn.Linear(lstm_hidden_size * 2, num_classes)  \n\n        self.dropout = nn.Dropout(dropout)\n\n        self.criterion = nn.CrossEntropyLoss()\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        # Get embeddings from BanglaBERT\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_states = outputs.last_hidden_state  # (batch_size, seq_len, 768)\n\n        # Pass through BiLSTM\n        lstm_out, _ = self.lstm(hidden_states)  # (batch_size, seq_len, hidden_size*2)\n        lstm_out = lstm_out[:, -1, :]  # Take the last time step output\n\n        # Pass through the classifier\n        logits = self.fc(self.dropout(lstm_out))  # (batch_size, num_classes)\n        # Compute loss if labels are provided\n        loss = None\n        if labels is not None:\n            loss = self.criterion(logits, labels)\n            \n        return (loss, logits) if loss is not None else logits","metadata":{"id":"JinYUE_RguxP","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:48:06.070980Z","iopub.execute_input":"2025-03-26T07:48:06.071355Z","iopub.status.idle":"2025-03-26T07:48:06.079269Z","shell.execute_reply.started":"2025-03-26T07:48:06.071319Z","shell.execute_reply":"2025-03-26T07:48:06.078343Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"model1 = BanglaBERT_LSTM_Multiclass()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0UHpkHBPg6ka","outputId":"905f0570-37ef-49db-b064-6ae46763a1d9","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:48:11.189952Z","iopub.execute_input":"2025-03-26T07:48:11.190261Z","iopub.status.idle":"2025-03-26T07:48:11.211390Z","shell.execute_reply.started":"2025-03-26T07:48:11.190237Z","shell.execute_reply":"2025-03-26T07:48:11.210774Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"model1.load_state_dict(torch.load(\"/kaggle/input/unber-1k/BB-LSTM-1.pth\"))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLejG4rVuC1e","outputId":"6fd29488-0df8-41c3-9d1a-0e24db624b7c","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:48:12.314337Z","iopub.execute_input":"2025-03-26T07:48:12.314669Z","iopub.status.idle":"2025-03-26T07:48:13.211966Z","shell.execute_reply.started":"2025-03-26T07:48:12.314639Z","shell.execute_reply":"2025-03-26T07:48:13.211035Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-56-1e0c26abe40f>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model1.load_state_dict(torch.load(\"/kaggle/input/unber-1k/BB-LSTM-1.pth\"))\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:48:15.265483Z","iopub.execute_input":"2025-03-26T07:48:15.265856Z","iopub.status.idle":"2025-03-26T07:48:15.273052Z","shell.execute_reply.started":"2025-03-26T07:48:15.265825Z","shell.execute_reply":"2025-03-26T07:48:15.272250Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"BanglaBERT_LSTM(\n  (bert): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (lstm): LSTM(768, 256, batch_first=True, dropout=0.3, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=1, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (criterion): BCEWithLogitsLoss()\n)"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"model1.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5NC3SlnzmxUu","outputId":"f9a8ce36-e0e2-40a2-c3c5-954fe0f3ccad","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:48:15.482307Z","iopub.execute_input":"2025-03-26T07:48:15.482604Z","iopub.status.idle":"2025-03-26T07:48:15.489391Z","shell.execute_reply.started":"2025-03-26T07:48:15.482580Z","shell.execute_reply":"2025-03-26T07:48:15.488507Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"BanglaBERT_LSTM_Multiclass(\n  (bert): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (lstm): LSTM(768, 256, batch_first=True, dropout=0.3, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=3, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (criterion): CrossEntropyLoss()\n)"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"text = [\n  \"দইরে টাইনে ছিরে ফেলাই দিবো\",\n  \"কেও হোটেলের মাল কে খাওয়ায় দিলো না\",\n  \"বোকা** ঘুমাচ্ছে\",\n  \"রোজার মাসে বের করে দিছে\",\n  \"বেয়াদব বেডা আমার গায়ে হাত দিছে\",\n  \"তুমি কথা দিয়েছিলে কখনো ছেড়ে যাবে না! কোথায় গেলো তোমার সেই কথা আর কোথাই বা তুমি...!!\",\n  \"ব্যর্থ প্রেম - Feeling sad তুমি তো ভালো না তোমার জন্য এত কষ্ট হয়\",\n  \"Koi tui? Tk dibi na Onek din to hoya geche Oda ma**dari\",\n  \"আমার Jelous...! আমার Loyalty\",\n  \"এক সপ্তাহ ছুটির পর অফিস এসে ওয়ার্ক লোড দেখার পর আমি\",\n  \"দোস্ত চল পাহাড়ে ট্রেকিং- এ যাই আইলসা ফ্রেন্ড: এমন সুবিধা আছে?\",\n  \"POV: আমরা দুই বোন আমাদের কোনো ভাই নাই\"\n]","metadata":{"id":"ykpzej7h7uty","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:31:53.443813Z","iopub.execute_input":"2025-03-26T07:31:53.444100Z","iopub.status.idle":"2025-03-26T07:31:53.448154Z","shell.execute_reply.started":"2025-03-26T07:31:53.444079Z","shell.execute_reply":"2025-03-26T07:31:53.447322Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from datasets import Dataset\nimport pandas as pd\n\ndef predict_uniclass(text):\n  inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n  inputs = {key: value.to(device) for key, value in inputs.items()} \n\n  with torch.no_grad():\n      logits = model(inputs['input_ids'], inputs['attention_mask'])\n\n  logits = logits.squeeze(0)\n  probabilities = torch.sigmoid(logits).tolist()\n\n  labels = ['Safe', 'Unsafe']\n  pred_val = [1 if probabilities[0] >= 0.5 else 0]\n\n  return labels[pred_val[0]]","metadata":{"id":"oMvAJGEBobtw","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T08:10:49.524340Z","iopub.execute_input":"2025-03-26T08:10:49.524630Z","iopub.status.idle":"2025-03-26T08:10:49.530075Z","shell.execute_reply.started":"2025-03-26T08:10:49.524607Z","shell.execute_reply":"2025-03-26T08:10:49.529156Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"predict_uniclass(text[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["0c897db21ab04082bdccfd49d037bdf2","d3717f7789bc40f68b813c94d3a5fc10","7d9f5a1e3ee344978c3c0ac901aa2e1d","8fc869d5596544868e7a59e1a34a4068","803a76dd401240129f81a5ba69ba638a","a3ba7c26bb1a4d57a23713263d72464b","83d2b8199e564f87a2549dc9ee3a40f1","5bd742d669df427db395b37fdb00cfa3","90f93880a915457eb5481d634c9b44aa","d103226b44ee448db91b768d11242fa5","171b106bca8645689269ce507aa9d0d9"]},"id":"7gH0k_4IrvIt","outputId":"14879c04-001d-4c40-8efa-76a1afcd93dc","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T08:10:56.663911Z","iopub.execute_input":"2025-03-26T08:10:56.664202Z","iopub.status.idle":"2025-03-26T08:10:56.680717Z","shell.execute_reply.started":"2025-03-26T08:10:56.664182Z","shell.execute_reply":"2025-03-26T08:10:56.679739Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"'Unsafe'"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel1.to(device)  # Move model to the correct device\n\ndef predict_multiclass(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    inputs = {key: value.to(device) for key, value in inputs.items()} \n\n    with torch.no_grad():\n        logits = model1(inputs['input_ids'], inputs['attention_mask'])\n\n    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n    predicted_class = torch.argmax(probabilities, dim=-1).item()\n    labels = ['Adult', 'Harmful', 'Suicidal']\n\n    return labels[predicted_class]","metadata":{"id":"L65_nEpwpUG4","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T08:08:29.250478Z","iopub.execute_input":"2025-03-26T08:08:29.250834Z","iopub.status.idle":"2025-03-26T08:08:29.262894Z","shell.execute_reply.started":"2025-03-26T08:08:29.250807Z","shell.execute_reply":"2025-03-26T08:08:29.261977Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"def predict(text):\n    pred = \"\"\n    mpred = \"\"\n    pred = predict_uniclass(text)\n    if pred=='Unsafe':\n        mpred = predict_multiclass(text)\n    \n    print(f\"Text: {text}\")\n    if pred==\"Unsafe\":\n        print(f\"Category: {pred}, Class: {mpred}\")\n    else:\n        print(f\"Category: {pred}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257,"referenced_widgets":["0e0e29b805bd492e8b12eb66d5fb0aa9","d00159c68e3a41909e293fe498292ecc","23d76f1eece04a2ba6f78c427feb085f","817ae316c1694dfab0e3e560d322dd4f","6769c745d7ca45bf87b88e2a21ad749e","d0f330849662421ca2e00277f8026c17","68458e7593bd4479b288b123d6efaed9","678d6c5ae0cc488da448a7c51661ff65","b0714a7eeb2f40c29d7078973148bb39","de513162f0a04ccd84bf44380944aa54","45d97d41f1cd4e6e896867afdb55275b"]},"id":"0G5nLT9XwMMA","outputId":"d9d6b029-9b05-4d29-fbcf-7c154cb9a678","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T08:18:07.103188Z","iopub.execute_input":"2025-03-26T08:18:07.103512Z","iopub.status.idle":"2025-03-26T08:18:07.108267Z","shell.execute_reply.started":"2025-03-26T08:18:07.103490Z","shell.execute_reply":"2025-03-26T08:18:07.107365Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"for txt in text:\n    print(predict(txt))","metadata":{"id":"Zy00GaB471D3","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T08:19:14.364809Z","iopub.execute_input":"2025-03-26T08:19:14.365125Z","iopub.status.idle":"2025-03-26T08:19:14.589457Z","shell.execute_reply.started":"2025-03-26T08:19:14.365101Z","shell.execute_reply":"2025-03-26T08:19:14.588561Z"}},"outputs":[{"name":"stdout","text":"Text: দইরে টাইনে ছিরে ফেলাই দিবো\nCategory: Unsafe, Class: Harmful\nNone\nText: কেও হোটেলের মাল কে খাওয়ায় দিলো না\nCategory: Unsafe, Class: Adult\nNone\nText: বোকা** ঘুমাচ্ছে\nCategory: Unsafe, Class: Adult\nNone\nText: রোজার মাসে বের করে দিছে\nCategory: Unsafe, Class: Adult\nNone\nText: বেয়াদব বেডা আমার গায়ে হাত দিছে\nCategory: Unsafe, Class: Adult\nNone\nText: তুমি কথা দিয়েছিলে কখনো ছেড়ে যাবে না! কোথায় গেলো তোমার সেই কথা আর কোথাই বা তুমি...!!\nCategory: Unsafe, Class: Suicidal\nNone\nText: ব্যর্থ প্রেম - Feeling sad তুমি তো ভালো না তোমার জন্য এত কষ্ট হয়\nCategory: Unsafe, Class: Suicidal\nNone\nText: Koi tui? Tk dibi na Onek din to hoya geche Oda ma**dari\nCategory: Unsafe, Class: Adult\nNone\nText: আমার Jelous...! আমার Loyalty\nCategory: Safe\nNone\nText: এক সপ্তাহ ছুটির পর অফিস এসে ওয়ার্ক লোড দেখার পর আমি\nCategory: Safe\nNone\nText: দোস্ত চল পাহাড়ে ট্রেকিং- এ যাই আইলসা ফ্রেন্ড: এমন সুবিধা আছে?\nCategory: Unsafe, Class: Harmful\nNone\nText: POV: আমরা দুই বোন আমাদের কোনো ভাই নাই\nCategory: Unsafe, Class: Adult\nNone\n","output_type":"stream"}],"execution_count":93}]}