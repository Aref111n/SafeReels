{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10873487,"sourceType":"datasetVersion","datasetId":6755884},{"sourceId":10953885,"sourceType":"datasetVersion","datasetId":6671304}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport transformers\nimport keras\nfrom keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:28.081808Z","iopub.execute_input":"2025-03-09T23:21:28.082089Z","iopub.status.idle":"2025-03-09T23:21:44.313692Z","shell.execute_reply.started":"2025-03-09T23:21:28.082057Z","shell.execute_reply":"2025-03-09T23:21:44.312856Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tensorflow.data import Dataset\nfrom tensorflow import keras\nfrom collections import Counter\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom skimage.transform import resize\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img, smart_resize\nfrom PIL import ImageFile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:44.314627Z","iopub.execute_input":"2025-03-09T23:21:44.315200Z","iopub.status.idle":"2025-03-09T23:21:44.819277Z","shell.execute_reply.started":"2025-03-09T23:21:44.315176Z","shell.execute_reply":"2025-03-09T23:21:44.818587Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport tensorflow as tf\nfrom transformers import AutoModel, AutoTokenizer\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:44.820021Z","iopub.execute_input":"2025-03-09T23:21:44.820560Z","iopub.status.idle":"2025-03-09T23:21:48.295034Z","shell.execute_reply.started":"2025-03-09T23:21:44.820536Z","shell.execute_reply":"2025-03-09T23:21:48.294102Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"VIDEO_PATH = \"/kaggle/input/unber-1111/UNBER-1k/Extracted_Frames\"  # Path for video frames\nAUDIO_PATH = \"/kaggle/input/unber-1111/UNBER-1k/Audios\"  # Path for audio files\nTEXT_CSV = \"/kaggle/input/unber-1111/UNBER-1k/text.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:48.296783Z","iopub.execute_input":"2025-03-09T23:21:48.297214Z","iopub.status.idle":"2025-03-09T23:21:48.300691Z","shell.execute_reply.started":"2025-03-09T23:21:48.297192Z","shell.execute_reply":"2025-03-09T23:21:48.299820Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\ntdf = pd.read_csv(TEXT_CSV)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:48.302176Z","iopub.execute_input":"2025-03-09T23:21:48.302534Z","iopub.status.idle":"2025-03-09T23:21:48.357020Z","shell.execute_reply.started":"2025-03-09T23:21:48.302505Z","shell.execute_reply":"2025-03-09T23:21:48.356420Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tdf['Visual texts'] = tdf['Visual texts'].fillna(\"কোন টেক্সট পাওয়া যায়নি\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:48.357871Z","iopub.execute_input":"2025-03-09T23:21:48.358157Z","iopub.status.idle":"2025-03-09T23:21:48.365802Z","shell.execute_reply.started":"2025-03-09T23:21:48.358129Z","shell.execute_reply":"2025-03-09T23:21:48.365157Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"tdf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:48.366502Z","iopub.execute_input":"2025-03-09T23:21:48.366691Z","iopub.status.idle":"2025-03-09T23:21:48.392065Z","shell.execute_reply.started":"2025-03-09T23:21:48.366674Z","shell.execute_reply":"2025-03-09T23:21:48.391394Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                  reel_id UnsafeType  \\\n0  www.facebook.com/reel/1000188341415358       Safe   \n1  www.facebook.com/reel/1006146964533997       Safe   \n2  www.facebook.com/reel/1007123741459823      Adult   \n3  www.facebook.com/reel/1007420607202244       Safe   \n4  www.facebook.com/reel/1008519870870927       Safe   \n\n                                     Visual texts  \n0  Me on my way to watch Oppenheimer After Berbie  \n1                          কোন টেক্সট পাওয়া যায়নি  \n2    বান্ধবী আমার লাগানির পিনিকে আছে Love in love  \n3    প্রত্যেকটা অফিসে এমন একজন কলিগ থাকবেই Laptop  \n4       হ্যালো শার্ক ট্যাঙ্ক বাংলাদেশ আই এম কামিং  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reel_id</th>\n      <th>UnsafeType</th>\n      <th>Visual texts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>www.facebook.com/reel/1000188341415358</td>\n      <td>Safe</td>\n      <td>Me on my way to watch Oppenheimer After Berbie</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>www.facebook.com/reel/1006146964533997</td>\n      <td>Safe</td>\n      <td>কোন টেক্সট পাওয়া যায়নি</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>www.facebook.com/reel/1007123741459823</td>\n      <td>Adult</td>\n      <td>বান্ধবী আমার লাগানির পিনিকে আছে Love in love</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>www.facebook.com/reel/1007420607202244</td>\n      <td>Safe</td>\n      <td>প্রত্যেকটা অফিসে এমন একজন কলিগ থাকবেই Laptop</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>www.facebook.com/reel/1008519870870927</td>\n      <td>Safe</td>\n      <td>হ্যালো শার্ক ট্যাঙ্ক বাংলাদেশ আই এম কামিং</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"tdf['UnsafeType'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:48.392791Z","iopub.execute_input":"2025-03-09T23:21:48.393023Z","iopub.status.idle":"2025-03-09T23:21:48.403421Z","shell.execute_reply.started":"2025-03-09T23:21:48.393005Z","shell.execute_reply":"2025-03-09T23:21:48.402679Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"UnsafeType\nSafe        441\nAdult       327\nHarmful     221\nSuicidal    122\nName: count, dtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"tdf['UnsafeType'], uniques = pd.factorize(tdf['UnsafeType'])\nuniques","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:48.404163Z","iopub.execute_input":"2025-03-09T23:21:48.404475Z","iopub.status.idle":"2025-03-09T23:21:48.422977Z","shell.execute_reply.started":"2025-03-09T23:21:48.404447Z","shell.execute_reply":"2025-03-09T23:21:48.422155Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['Safe', 'Adult', 'Harmful', 'Suicidal'], dtype='object')"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"pip install noisereduce","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:48.423718Z","iopub.execute_input":"2025-03-09T23:21:48.424000Z","iopub.status.idle":"2025-03-09T23:21:52.847119Z","shell.execute_reply.started":"2025-03-09T23:21:48.423973Z","shell.execute_reply":"2025-03-09T23:21:52.846196Z"}},"outputs":[{"name":"stdout","text":"Collecting noisereduce\n  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.13.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.7.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.67.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.4.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->noisereduce) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->noisereduce) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->noisereduce) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->noisereduce) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->noisereduce) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->noisereduce) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->noisereduce) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->noisereduce) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->noisereduce) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->noisereduce) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->noisereduce) (2024.2.0)\nDownloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\nInstalling collected packages: noisereduce\nSuccessfully installed noisereduce-3.0.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport noisereduce as nr\nimport soundfile as sf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:52.848137Z","iopub.execute_input":"2025-03-09T23:21:52.848494Z","iopub.status.idle":"2025-03-09T23:21:52.996769Z","shell.execute_reply.started":"2025-03-09T23:21:52.848460Z","shell.execute_reply":"2025-03-09T23:21:52.996072Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"IMG_SIZE = (224, 224)\nNUM_CLASSES = 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:52.997577Z","iopub.execute_input":"2025-03-09T23:21:52.998640Z","iopub.status.idle":"2025-03-09T23:21:53.002096Z","shell.execute_reply.started":"2025-03-09T23:21:52.998614Z","shell.execute_reply":"2025-03-09T23:21:53.001338Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def load_video_frames(folder_path):\n    frames = []\n    frame_files = sorted(os.listdir(video_folder))\n    for file in frame_files:\n        img_path = os.path.join(video_folder, file)\n        img = load_img(img_path, target_size=IMG_SIZE)\n        img = img_to_array(img)\n        frames.append(img)\n\n    return np.array(frames)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:53.005214Z","iopub.execute_input":"2025-03-09T23:21:53.005503Z","iopub.status.idle":"2025-03-09T23:21:53.019090Z","shell.execute_reply.started":"2025-03-09T23:21:53.005482Z","shell.execute_reply":"2025-03-09T23:21:53.018361Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def process_audio_file(file_path, target_length=5, sample_rate=22050, n_mfcc=13, n_chroma=12, n_spectral_contrast=6, target_length_features=20):\n    # Load audio file\n    audio, sr = librosa.load(file_path, sr=sample_rate)\n\n    # Trim or pad audio to target length\n    target_samples = target_length * sr\n    if len(audio) > target_samples:\n        audio = audio[:target_samples]  # Trim\n    else:\n        padding = target_samples - len(audio)\n        audio = np.pad(audio, (0, padding), mode='constant')  # Pad with silence\n\n    # Normalize audio (zero mean, unit variance)\n    mean = np.mean(audio)\n    std = np.std(audio)\n    safe_std = max(std, 1e-8)  # Avoid division by zero\n    audio = (audio - mean) / safe_std\n\n    # Apply noise reduction\n    reduced_noise_audio = nr.reduce_noise(y=audio, sr=sr)\n\n    if not np.isfinite(reduced_noise_audio).all():\n        print(\"Warning: Noise reduction produced NaN/Inf values, reverting to original audio.\")\n        reduced_noise_audio = audio  # Use original if noise reduction fails\n    \n    reduced_noise_audio = np.nan_to_num(reduced_noise_audio)\n\n    # Feature Extraction\n    def truncate_or_pad(feature, target_length_features):\n        \"\"\"Ensures features have a fixed length by truncating or padding.\"\"\"\n        if feature.shape[1] > target_length_features:\n            return feature[:, :target_length_features]\n        else:\n            return np.pad(feature, ((0, 0), (0, target_length_features - feature.shape[1])), mode='constant')\n\n    # Extract MFCCs (13 coefficients)\n    mfcc = librosa.feature.mfcc(y=reduced_noise_audio, sr=sr, n_mfcc=n_mfcc)\n    mfcc = truncate_or_pad(mfcc, target_length_features)\n\n    # Extract Chroma Features (12 pitch classes)\n    chroma = librosa.feature.chroma_stft(y=reduced_noise_audio, sr=sr, n_chroma=n_chroma)\n    chroma = truncate_or_pad(chroma, target_length_features)\n\n    # Extract Spectral Centroid\n    spectral_centroid = librosa.feature.spectral_centroid(y=reduced_noise_audio, sr=sr)\n    spectral_centroid = truncate_or_pad(spectral_centroid, target_length_features)\n\n    # Extract Spectral Contrast (6 bands)\n    spectral_contrast = librosa.feature.spectral_contrast(y=reduced_noise_audio, sr=sr, n_bands=n_spectral_contrast)\n    spectral_contrast = truncate_or_pad(spectral_contrast, target_length_features)\n\n    # Extract Spectrogram (Magnitude Spectrogram)\n    spectrogram = np.abs(librosa.stft(reduced_noise_audio))\n    spectrogram = truncate_or_pad(spectrogram, target_length_features)\n\n    # Flatten all features into a single vector\n    feature_vector = np.concatenate([\n        mfcc.flatten(),\n        chroma.flatten(),\n        spectral_centroid.flatten(),\n        spectral_contrast.flatten(),\n        spectrogram.flatten()\n    ])\n\n    return feature_vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:53.020474Z","iopub.execute_input":"2025-03-09T23:21:53.020711Z","iopub.status.idle":"2025-03-09T23:21:53.030906Z","shell.execute_reply.started":"2025-03-09T23:21:53.020684Z","shell.execute_reply":"2025-03-09T23:21:53.030236Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"X_video, X_audio, X_text, y = [], [], [], []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:53.032010Z","iopub.execute_input":"2025-03-09T23:21:53.032365Z","iopub.status.idle":"2025-03-09T23:21:53.049704Z","shell.execute_reply.started":"2025-03-09T23:21:53.032330Z","shell.execute_reply":"2025-03-09T23:21:53.049098Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"for _, row in tdf.iterrows():\n    reel_id = row[\"reel_id\"].split(\"/\")[-1]  \n    label = row[\"UnsafeType\"]  \n\n    video_folder = os.path.join(VIDEO_PATH, reel_id)\n    audio_file = os.path.join(AUDIO_PATH, f\"audio{reel_id}.wav\")\n\n    if os.path.isdir(video_folder) and os.path.exists(audio_file):\n        frames = load_video_frames(video_folder)  \n        processed_audio = process_audio_file(audio_file)  \n        text_feature = row[\"Visual texts\"]  \n\n        X_video.append(frames)\n        X_audio.append(processed_audio)\n        X_text.append(text_feature)\n        y.append(label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:21:53.050469Z","iopub.execute_input":"2025-03-09T23:21:53.050663Z","iopub.status.idle":"2025-03-09T23:25:49.417947Z","shell.execute_reply.started":"2025-03-09T23:21:53.050646Z","shell.execute_reply":"2025-03-09T23:25:49.417155Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/noisereduce/spectralgate/nonstationary.py:70: RuntimeWarning: divide by zero encountered in divide\n  sig_mult_above_thresh = (abs_sig_stft - sig_stft_smooth) / sig_stft_smooth\n/usr/local/lib/python3.10/dist-packages/noisereduce/spectralgate/nonstationary.py:70: RuntimeWarning: invalid value encountered in divide\n  sig_mult_above_thresh = (abs_sig_stft - sig_stft_smooth) / sig_stft_smooth\n/usr/local/lib/python3.10/dist-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n  return pitch_tuning(\n","output_type":"stream"},{"name":"stdout","text":"Warning: Noise reduction produced NaN/Inf values, reverting to original audio.\nWarning: Noise reduction produced NaN/Inf values, reverting to original audio.\nWarning: Noise reduction produced NaN/Inf values, reverting to original audio.\nWarning: Noise reduction produced NaN/Inf values, reverting to original audio.\nWarning: Noise reduction produced NaN/Inf values, reverting to original audio.\nWarning: Noise reduction produced NaN/Inf values, reverting to original audio.\nWarning: Noise reduction produced NaN/Inf values, reverting to original audio.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(len(X_video), len(X_audio), len(X_text), len(y))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:49.418930Z","iopub.execute_input":"2025-03-09T23:25:49.419780Z","iopub.status.idle":"2025-03-09T23:25:49.424734Z","shell.execute_reply.started":"2025-03-09T23:25:49.419743Z","shell.execute_reply":"2025-03-09T23:25:49.424023Z"}},"outputs":[{"name":"stdout","text":"1111 1111 1111 1111\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"X_video = np.array(X_video) \nX_audio = np.array(X_audio, dtype=np.float32)\nX_text = np.array(X_text)  \ny = np.array(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:49.425503Z","iopub.execute_input":"2025-03-09T23:25:49.425747Z","iopub.status.idle":"2025-03-09T23:25:50.455728Z","shell.execute_reply.started":"2025-03-09T23:25:49.425727Z","shell.execute_reply":"2025-03-09T23:25:50.454993Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"X_video.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.456409Z","iopub.execute_input":"2025-03-09T23:25:50.456646Z","iopub.status.idle":"2025-03-09T23:25:50.461600Z","shell.execute_reply.started":"2025-03-09T23:25:50.456626Z","shell.execute_reply":"2025-03-09T23:25:50.460773Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(1111, 5, 224, 224, 3)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n\n# # Initialize the scaler\n# scaler = StandardScaler()\n\n# # Scale X_video, X_audio, and X_text\n# X_video_scaled = scaler.fit_transform(X_video.reshape(X_video.shape[0], -1))  # Flatten video frames\n# X_audio_scaled = scaler.fit_transform(X_audio.reshape(X_audio.shape[0], -1))  # Flatten audio features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.462337Z","iopub.execute_input":"2025-03-09T23:25:50.462642Z","iopub.status.idle":"2025-03-09T23:25:50.476677Z","shell.execute_reply.started":"2025-03-09T23:25:50.462613Z","shell.execute_reply":"2025-03-09T23:25:50.475734Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# X_video = X_video.reshape(-1, 224, 224, 3)\n# X_audio = np.repeat(X_audio, 5, axis=0)\n# X_text = np.repeat(X_text, 5, axis=0)\n# y = np.repeat(y, 5, axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.477435Z","iopub.execute_input":"2025-03-09T23:25:50.477722Z","iopub.status.idle":"2025-03-09T23:25:50.493853Z","shell.execute_reply.started":"2025-03-09T23:25:50.477701Z","shell.execute_reply":"2025-03-09T23:25:50.493120Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"X_video.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.494520Z","iopub.execute_input":"2025-03-09T23:25:50.494774Z","iopub.status.idle":"2025-03-09T23:25:50.514993Z","shell.execute_reply.started":"2025-03-09T23:25:50.494754Z","shell.execute_reply":"2025-03-09T23:25:50.514347Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(1111, 5, 224, 224, 3)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"X_audio.shape ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.515724Z","iopub.execute_input":"2025-03-09T23:25:50.515978Z","iopub.status.idle":"2025-03-09T23:25:50.531827Z","shell.execute_reply.started":"2025-03-09T23:25:50.515947Z","shell.execute_reply":"2025-03-09T23:25:50.531205Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(1111, 21160)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"X_audio = np.expand_dims(X_audio, axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.532570Z","iopub.execute_input":"2025-03-09T23:25:50.532850Z","iopub.status.idle":"2025-03-09T23:25:50.546798Z","shell.execute_reply.started":"2025-03-09T23:25:50.532824Z","shell.execute_reply":"2025-03-09T23:25:50.545955Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"X_audio.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.547555Z","iopub.execute_input":"2025-03-09T23:25:50.547740Z","iopub.status.idle":"2025-03-09T23:25:50.564083Z","shell.execute_reply.started":"2025-03-09T23:25:50.547724Z","shell.execute_reply":"2025-03-09T23:25:50.563382Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(1111, 21160, 1)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"X_text.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.564785Z","iopub.execute_input":"2025-03-09T23:25:50.565028Z","iopub.status.idle":"2025-03-09T23:25:50.581192Z","shell.execute_reply.started":"2025-03-09T23:25:50.565004Z","shell.execute_reply":"2025-03-09T23:25:50.580573Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(1111,)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"y.shape ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.581865Z","iopub.execute_input":"2025-03-09T23:25:50.582040Z","iopub.status.idle":"2025-03-09T23:25:50.596499Z","shell.execute_reply.started":"2025-03-09T23:25:50.582024Z","shell.execute_reply":"2025-03-09T23:25:50.595898Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(1111,)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Step 1: Split into train and temp (val + test)\nX_train_vid, X_temp_vid, X_train_aud, X_temp_aud, X_train_text, X_temp_text, y_train, y_temp = train_test_split(\n    X_video, X_audio, X_text, y, test_size=0.2, random_state=42, shuffle=True\n)\n\n# Step 2: Split temp into val and test\nX_val_vid, X_test_vid, X_val_aud, X_test_aud, X_val_text, X_test_text, y_val, y_test = train_test_split(\n    X_temp_vid, X_temp_aud, X_temp_text, y_temp, test_size=0.5, random_state=42, shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:50.597145Z","iopub.execute_input":"2025-03-09T23:25:50.597404Z","iopub.status.idle":"2025-03-09T23:25:51.680775Z","shell.execute_reply.started":"2025-03-09T23:25:50.597386Z","shell.execute_reply":"2025-03-09T23:25:51.679739Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## Text Preprocessing","metadata":{}},{"cell_type":"code","source":"model_name = \"csebuetnlp/banglabert\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:51.681775Z","iopub.execute_input":"2025-03-09T23:25:51.682105Z","iopub.status.idle":"2025-03-09T23:25:51.685980Z","shell.execute_reply.started":"2025-03-09T23:25:51.682073Z","shell.execute_reply":"2025-03-09T23:25:51.685258Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from transformers import AutoModelForPreTraining, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:51.686939Z","iopub.execute_input":"2025-03-09T23:25:51.687180Z","iopub.status.idle":"2025-03-09T23:25:53.558321Z","shell.execute_reply.started":"2025-03-09T23:25:51.687162Z","shell.execute_reply":"2025-03-09T23:25:53.557362Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c42e2ad632840ad85cf8f4647f37084"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/586 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31fa2c8aa88e4007b6be851c9f182a6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/528k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e38fb1f896c40878adbd666ecb1788d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"584ad485878245f792286e4c62aaf12d"}},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"train_encodings = tokenizer(list(X_train_text), max_length=512, truncation=True, padding=\"max_length\", return_tensors='tf')\nprint(np.shape(train_encodings[\"input_ids\"]))\n\nval_encodings = tokenizer(list(X_val_text), max_length=512, truncation=True, padding=\"max_length\", return_tensors='tf')\nprint(np.shape(val_encodings[\"input_ids\"]))\n\ntest_encodings = tokenizer(list(X_test_text), max_length=512, truncation=True, padding=\"max_length\", return_tensors='tf')\nprint(np.shape(test_encodings[\"input_ids\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:53.559304Z","iopub.execute_input":"2025-03-09T23:25:53.559638Z","iopub.status.idle":"2025-03-09T23:25:54.054829Z","shell.execute_reply.started":"2025-03-09T23:25:53.559615Z","shell.execute_reply":"2025-03-09T23:25:54.054046Z"}},"outputs":[{"name":"stdout","text":"(888, 512)\n(111, 512)\n(112, 512)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Audio Preprocessing","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.models import Model\n\n# Define Autoencoder (512-D encoded representation)\ndef build_audio_autoencoder(input_dim=21160, latent_dim=512):\n    input_audio = Input(shape=(input_dim,))\n    \n    # Encoder\n    encoded = Dense(256, activation='relu')(input_audio)\n    encoded = Dense(latent_dim, activation='relu')(encoded)  # Compressed 512-D representation\n\n    # Decoder\n    decoded = Dense(256, activation='relu')(encoded)\n    decoded = Dense(input_dim, activation='sigmoid')(decoded)  # Reconstruct original input\n\n    autoencoder = Model(input_audio, decoded)\n    encoder = Model(input_audio, encoded)  # This will be used for fusion\n\n    autoencoder.compile(optimizer='adam', loss='mse')\n    return autoencoder, encoder\n\n# Create the autoencoder\nautoencoder, audio_encoder = build_audio_autoencoder()\nautoencoder.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:54.055646Z","iopub.execute_input":"2025-03-09T23:25:54.055955Z","iopub.status.idle":"2025-03-09T23:25:55.416737Z","shell.execute_reply.started":"2025-03-09T23:25:54.055923Z","shell.execute_reply":"2025-03-09T23:25:55.416071Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21160\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m5,417,216\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21160\u001b[0m)               │       \u001b[38;5;34m5,438,120\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21160</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,417,216</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21160</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,438,120</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,118,248\u001b[0m (42.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,118,248</span> (42.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,118,248\u001b[0m (42.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,118,248</span> (42.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Callbacks\nearly_stopping = EarlyStopping(\n    monitor='val_loss', patience=10, restore_best_weights=True, verbose=1\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1\n)\n\n# Train the Autoencoder\nautoencoder.fit(\n    X_train_aud, X_train_aud,\n    epochs=100, batch_size=16, shuffle=True,\n    validation_data=(X_val_aud, X_val_aud),\n    callbacks=[early_stopping, reduce_lr]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:25:55.417533Z","iopub.execute_input":"2025-03-09T23:25:55.417776Z","iopub.status.idle":"2025-03-09T23:26:01.723106Z","shell.execute_reply.started":"2025-03-09T23:25:55.417744Z","shell.execute_reply":"2025-03-09T23:26:01.722220Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 9353.9297 - val_loss: 9402.5410 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9093.8721 - val_loss: 9402.5420 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9476.0264 - val_loss: 9402.5420 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9246.7637 - val_loss: 9402.5420 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9560.3887 - val_loss: 9402.5430 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m55/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9574.5879\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9565.2480 - val_loss: 9402.5420 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9530.7637 - val_loss: 9402.5439 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9642.0781 - val_loss: 9402.5430 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9890.0898 - val_loss: 9402.5430 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8614.4600 - val_loss: 9402.5430 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m54/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9578.5312\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9564.2500 - val_loss: 9402.5430 - learning_rate: 5.0000e-04\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x790edc2e5d20>"},"metadata":{}}],"execution_count":33},{"cell_type":"markdown","source":"## Image Processing","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom transformers import ViTModel, ViTFeatureExtractor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:31:16.511019Z","iopub.execute_input":"2025-03-09T23:31:16.511373Z","iopub.status.idle":"2025-03-09T23:31:17.265423Z","shell.execute_reply.started":"2025-03-09T23:31:16.511340Z","shell.execute_reply":"2025-03-09T23:31:17.264509Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"class ViT_LSTM_Model(nn.Module):\n    def __init__(self, vit_model, lstm_hidden_size=256, num_classes=4):\n        super(ViT_LSTM_Model, self).__init__()\n        self.vit = vit_model\n        self.lstm_hidden_size = lstm_hidden_size\n        self.num_classes = num_classes\n\n        # Freeze ViT parameters (only train LSTM and classifier)\n        for param in self.vit.parameters():\n            param.requires_grad = False\n\n        # LSTM to process ViT feature sequences\n        self.lstm = nn.LSTM(input_size=768, hidden_size=lstm_hidden_size, num_layers=1, batch_first=True)\n\n        # Fully connected classifier\n        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n\n    def forward(self, x):\n        batch_size, num_frames, c, h, w = x.shape\n        x = x.view(batch_size * num_frames, c, h, w)\n\n        with torch.no_grad():  # Extract features using ViT\n            features = self.vit(x).last_hidden_state[:, 0, :]\n\n        features = features.view(batch_size, num_frames, -1)  # Reshape back to (batch, num_frames, 768)\n        lstm_out, _ = self.lstm(features)  # LSTM processing\n        final_output = lstm_out[:, -1, :]  # Take the last LSTM output\n\n        return final_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:16:39.219890Z","iopub.execute_input":"2025-03-10T00:16:39.220181Z","iopub.status.idle":"2025-03-10T00:16:39.226149Z","shell.execute_reply.started":"2025-03-10T00:16:39.220161Z","shell.execute_reply":"2025-03-10T00:16:39.225364Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nvit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\nvit_lstm_model = ViT_LSTM_Model(vit_model).to(device)\nvit_lstm_model.load_state_dict(torch.load(\"/kaggle/input/unber-1k/vit_lstm_model.pth\", map_location=device))\nvit_lstm_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:16:45.529734Z","iopub.execute_input":"2025-03-10T00:16:45.530130Z","iopub.status.idle":"2025-03-10T00:16:46.230934Z","shell.execute_reply.started":"2025-03-10T00:16:45.530097Z","shell.execute_reply":"2025-03-10T00:16:46.230023Z"}},"outputs":[{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n<ipython-input-49-c727fe798d63>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  vit_lstm_model.load_state_dict(torch.load(\"/kaggle/input/unber-1k/vit_lstm_model.pth\", map_location=device))\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"ViT_LSTM_Model(\n  (vit): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): ViTPatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ViTLayer(\n          (attention): ViTSdpaAttention(\n            (attention): ViTSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (pooler): ViTPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (lstm): LSTM(768, 256, batch_first=True)\n  (fc): Linear(in_features=256, out_features=4, bias=True)\n)"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:16:59.715410Z","iopub.execute_input":"2025-03-10T00:16:59.715714Z","iopub.status.idle":"2025-03-10T00:16:59.719736Z","shell.execute_reply.started":"2025-03-10T00:16:59.715692Z","shell.execute_reply":"2025-03-10T00:16:59.718819Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"class VideoDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        video = self.X[idx]  # Shape: (num_frames, 224, 224, 3)\n        label = self.y[idx]\n\n        # Convert to tensor and normalize\n        video = torch.tensor(video, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0  # (num_frames, 3, 224, 224)\n        return video, torch.tensor(label, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:17:00.335785Z","iopub.execute_input":"2025-03-10T00:17:00.336083Z","iopub.status.idle":"2025-03-10T00:17:00.341257Z","shell.execute_reply.started":"2025-03-10T00:17:00.336062Z","shell.execute_reply":"2025-03-10T00:17:00.340402Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"train_dataset = VideoDataset(X_train_vid, y_train)\nval_dataset = VideoDataset(X_val_vid, y_val)\ntest_dataset = VideoDataset(X_test_vid, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:17:02.200336Z","iopub.execute_input":"2025-03-10T00:17:02.200657Z","iopub.status.idle":"2025-03-10T00:17:02.204957Z","shell.execute_reply.started":"2025-03-10T00:17:02.200624Z","shell.execute_reply":"2025-03-10T00:17:02.203845Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:17:02.421188Z","iopub.execute_input":"2025-03-10T00:17:02.421694Z","iopub.status.idle":"2025-03-10T00:17:02.427785Z","shell.execute_reply.started":"2025-03-10T00:17:02.421655Z","shell.execute_reply":"2025-03-10T00:17:02.426830Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"with torch.no_grad():\n    for videos, labels in test_loader:\n        videos, labels = videos.to(device), labels.to(device)\n        outputs = vit_lstm_model(videos)\n        print(outputs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:18:42.856594Z","iopub.execute_input":"2025-03-10T00:18:42.856898Z","iopub.status.idle":"2025-03-10T00:18:46.408987Z","shell.execute_reply.started":"2025-03-10T00:18:42.856876Z","shell.execute_reply":"2025-03-10T00:18:46.408063Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\ntorch.Size([8, 256])\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"import torch\n\ndef extract_visual_features(model, data_loader, device):\n    all_features = []\n\n    with torch.no_grad():  # Disable gradient computation for efficiency\n        for videos, _ in data_loader:  # Only extracting features, so labels are ignored\n            videos = videos.to(device)\n            features = model(videos)  # Shape: (batch_size, 256) from ViT-LSTM\n            all_features.append(features.cpu())  # Move to CPU and store\n\n    return torch.cat(all_features, dim=0)  # Stack all feature tensors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:24:35.848967Z","iopub.execute_input":"2025-03-10T00:24:35.849462Z","iopub.status.idle":"2025-03-10T00:24:35.854869Z","shell.execute_reply.started":"2025-03-10T00:24:35.849390Z","shell.execute_reply":"2025-03-10T00:24:35.853967Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"X_train_vid_f = extract_visual_features(vit_lstm_model, train_loader, device)\n\nprint(\"Extracted Visual Features Shape:\", X_train_vid_f.shape)  # (num_samples, 256)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:25:51.300234Z","iopub.execute_input":"2025-03-10T00:25:51.300561Z","iopub.status.idle":"2025-03-10T00:26:17.858583Z","shell.execute_reply.started":"2025-03-10T00:25:51.300536Z","shell.execute_reply":"2025-03-10T00:26:17.857821Z"}},"outputs":[{"name":"stdout","text":"Extracted Visual Features Shape: torch.Size([888, 256])\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"X_train_vid_f = extract_visual_features(vit_lstm_model, train_loader, device)\nX_test_vid_f = extract_visual_features(vit_lstm_model, test_loader, device)\nX_val_vid_f = extract_visual_features(vit_lstm_model, val_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:27:22.422195Z","iopub.execute_input":"2025-03-10T00:27:22.422611Z","iopub.status.idle":"2025-03-10T00:27:55.784781Z","shell.execute_reply.started":"2025-03-10T00:27:22.422583Z","shell.execute_reply":"2025-03-10T00:27:55.783786Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"print(X_train_vid_f.shape)\nprint(X_test_vid_f.shape)\nprint(X_val_vid_f.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:28:12.307548Z","iopub.execute_input":"2025-03-10T00:28:12.307834Z","iopub.status.idle":"2025-03-10T00:28:12.312671Z","shell.execute_reply.started":"2025-03-10T00:28:12.307813Z","shell.execute_reply":"2025-03-10T00:28:12.311999Z"}},"outputs":[{"name":"stdout","text":"torch.Size([888, 256])\ntorch.Size([112, 256])\ntorch.Size([111, 256])\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"X_train_aud_f = audio_encoder.predict(X_train_aud)  \nX_val_aud_f = audio_encoder.predict(X_val_aud)\nX_test_aud_f = audio_encoder.predict(X_test_aud)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:28:23.302684Z","iopub.execute_input":"2025-03-10T00:28:23.302971Z","iopub.status.idle":"2025-03-10T00:28:24.070320Z","shell.execute_reply.started":"2025-03-10T00:28:23.302950Z","shell.execute_reply":"2025-03-10T00:28:24.069567Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"print(X_train_aud_f.shape)\nprint(X_test_aud_f.shape)\nprint(X_val_aud_f.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:28:46.703489Z","iopub.execute_input":"2025-03-10T00:28:46.703799Z","iopub.status.idle":"2025-03-10T00:28:46.708476Z","shell.execute_reply.started":"2025-03-10T00:28:46.703778Z","shell.execute_reply":"2025-03-10T00:28:46.707686Z"}},"outputs":[{"name":"stdout","text":"(888, 512)\n(112, 512)\n(111, 512)\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom transformers import AutoModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:28:56.069938Z","iopub.execute_input":"2025-03-10T00:28:56.070223Z","iopub.status.idle":"2025-03-10T00:28:56.074306Z","shell.execute_reply.started":"2025-03-10T00:28:56.070201Z","shell.execute_reply":"2025-03-10T00:28:56.073531Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"model_name = \"/kaggle/input/unber-1k/ReelBBert-20250215T144010Z-001/ReelBBert\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nbanglabert_model = AutoModel.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:29:16.418909Z","iopub.execute_input":"2025-03-10T00:29:16.419200Z","iopub.status.idle":"2025-03-10T00:29:17.734318Z","shell.execute_reply.started":"2025-03-10T00:29:16.419178Z","shell.execute_reply":"2025-03-10T00:29:17.733650Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"def get_text_embedding(texts):\n    \"\"\"Extracts [CLS] embeddings for a list of texts using BanglaBERT.\"\"\"\n    banglabert_model.eval()  # Set model to evaluation mode\n    embeddings = []\n\n    with torch.no_grad():\n        for text in texts:\n            inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n            outputs = banglabert_model(**inputs)\n            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # Extract [CLS] token\n            embeddings.append(cls_embedding)\n\n    return np.array(embeddings) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:29:25.551840Z","iopub.execute_input":"2025-03-10T00:29:25.552122Z","iopub.status.idle":"2025-03-10T00:29:25.557044Z","shell.execute_reply.started":"2025-03-10T00:29:25.552101Z","shell.execute_reply":"2025-03-10T00:29:25.555934Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"train_emb = get_text_embedding(X_train_text) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:29:26.917694Z","iopub.execute_input":"2025-03-10T00:29:26.917977Z","iopub.status.idle":"2025-03-10T00:38:27.872145Z","shell.execute_reply.started":"2025-03-10T00:29:26.917957Z","shell.execute_reply":"2025-03-10T00:38:27.871380Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"train_emb.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:38:31.474685Z","iopub.execute_input":"2025-03-10T00:38:31.474977Z","iopub.status.idle":"2025-03-10T00:38:31.479954Z","shell.execute_reply.started":"2025-03-10T00:38:31.474956Z","shell.execute_reply":"2025-03-10T00:38:31.479080Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"(888, 768)"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"test_emb = get_text_embedding(X_test_text)\nval_emb = get_text_embedding(X_val_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:38:33.283748Z","iopub.execute_input":"2025-03-10T00:38:33.284032Z","iopub.status.idle":"2025-03-10T00:40:29.924512Z","shell.execute_reply.started":"2025-03-10T00:38:33.284011Z","shell.execute_reply":"2025-03-10T00:40:29.923524Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"X_train_text_f = train_emb\nX_test_text_f = test_emb\nX_val_text_f = val_emb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:40:45.783914Z","iopub.execute_input":"2025-03-10T00:40:45.784239Z","iopub.status.idle":"2025-03-10T00:40:45.787685Z","shell.execute_reply.started":"2025-03-10T00:40:45.784213Z","shell.execute_reply":"2025-03-10T00:40:45.786907Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"print(X_train_text_f.shape)\nprint(X_test_text_f.shape)\nprint(X_val_text_f.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:40:47.341702Z","iopub.execute_input":"2025-03-10T00:40:47.342023Z","iopub.status.idle":"2025-03-10T00:40:47.346862Z","shell.execute_reply.started":"2025-03-10T00:40:47.342001Z","shell.execute_reply":"2025-03-10T00:40:47.346124Z"}},"outputs":[{"name":"stdout","text":"(888, 768)\n(112, 768)\n(111, 768)\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, Concatenate, BatchNormalization, Dropout, GlobalAveragePooling1D","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:43:58.647793Z","iopub.execute_input":"2025-03-10T00:43:58.648083Z","iopub.status.idle":"2025-03-10T00:43:58.652224Z","shell.execute_reply.started":"2025-03-10T00:43:58.648062Z","shell.execute_reply":"2025-03-10T00:43:58.651362Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"def attention_based_fusion():\n    # Image Input (2048-D from ResNet)\n    img_input = Input(shape=(256,), name=\"image_input\")\n\n    # Audio Input (256-D from Autoencoder)\n    audio_input = Input(shape=(512,), name=\"audio_input\")\n\n    # Precomputed Text Embeddings (768-D from BanglaBERT)\n    text_input = Input(shape=(768,), name=\"text_input\")  \n\n    # Concatenate Features\n    fused_features = Concatenate()([img_input, audio_input, text_input])\n\n    # Fully Connected Layers\n    X = BatchNormalization()(fused_features)\n    X = Dense(128, activation='tanh')(X)\n    X = Dropout(0.3)(X)\n    X = Dense(64, activation='tanh')(X)\n    X = Dense(4, activation='softmax', name=\"output\")(X)  # Properly connected output layer\n\n    # Define Model\n    model = Model(inputs=[img_input, audio_input, text_input], outputs=X)  \n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:44:57.916965Z","iopub.execute_input":"2025-03-10T00:44:57.917246Z","iopub.status.idle":"2025-03-10T00:44:57.922531Z","shell.execute_reply.started":"2025-03-10T00:44:57.917225Z","shell.execute_reply":"2025-03-10T00:44:57.921673Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"model = attention_based_fusion()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:44:59.817050Z","iopub.execute_input":"2025-03-10T00:44:59.817378Z","iopub.status.idle":"2025-03-10T00:44:59.854998Z","shell.execute_reply.started":"2025-03-10T00:44:59.817344Z","shell.execute_reply":"2025-03-10T00:44:59.854129Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:45:00.597916Z","iopub.execute_input":"2025-03-10T00:45:00.598241Z","iopub.status.idle":"2025-03-10T00:45:00.618072Z","shell.execute_reply.started":"2025-03-10T00:45:00.598214Z","shell.execute_reply":"2025-03-10T00:45:00.617237Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ image_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ audio_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ audio_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │                        │                │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │          \u001b[38;5;34m6,144\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m196,736\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m260\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ image_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ audio_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ audio_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │                        │                │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">196,736</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m211,396\u001b[0m (825.77 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,396</span> (825.77 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m208,324\u001b[0m (813.77 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208,324</span> (813.77 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:45:15.543684Z","iopub.execute_input":"2025-03-10T00:45:15.544005Z","iopub.status.idle":"2025-03-10T00:45:15.551890Z","shell.execute_reply.started":"2025-03-10T00:45:15.543978Z","shell.execute_reply":"2025-03-10T00:45:15.551144Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"history = model.fit(\n    x=[X_train_vid_f, X_train_aud_f, X_train_text_f],  # Training inputs\n    y=y_train,                                 # Training labels\n    batch_size=32,\n    epochs=20,\n    validation_data=([X_val_vid_f, X_val_aud_f, X_val_text_f], y_val),  # Validation inputs and labels\n    shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:46:05.164554Z","iopub.execute_input":"2025-03-10T00:46:05.164845Z","iopub.status.idle":"2025-03-10T00:46:13.217695Z","shell.execute_reply.started":"2025-03-10T00:46:05.164823Z","shell.execute_reply":"2025-03-10T00:46:13.217011Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 0.6460 - loss: 0.8543 - val_accuracy: 0.5856 - val_loss: 0.9888\nEpoch 2/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.5885 - val_accuracy: 0.7387 - val_loss: 0.7015\nEpoch 3/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7904 - loss: 0.5409 - val_accuracy: 0.7207 - val_loss: 0.7283\nEpoch 4/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.5087 - val_accuracy: 0.7297 - val_loss: 0.5855\nEpoch 5/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7906 - loss: 0.4931 - val_accuracy: 0.7838 - val_loss: 0.5703\nEpoch 6/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.4113 - val_accuracy: 0.7658 - val_loss: 0.5571\nEpoch 7/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3988 - val_accuracy: 0.7297 - val_loss: 0.6319\nEpoch 8/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.4051 - val_accuracy: 0.7568 - val_loss: 0.6316\nEpoch 9/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3697 - val_accuracy: 0.7387 - val_loss: 0.6847\nEpoch 10/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.3602 - val_accuracy: 0.7387 - val_loss: 0.6537\nEpoch 11/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8790 - loss: 0.2997 - val_accuracy: 0.7928 - val_loss: 0.5728\nEpoch 12/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2884 - val_accuracy: 0.7658 - val_loss: 0.6827\nEpoch 13/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.2646 - val_accuracy: 0.7387 - val_loss: 0.7018\nEpoch 14/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2303 - val_accuracy: 0.7568 - val_loss: 0.5965\nEpoch 15/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.2874 - val_accuracy: 0.7658 - val_loss: 0.8025\nEpoch 16/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.1841 - val_accuracy: 0.7207 - val_loss: 0.7109\nEpoch 17/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2038 - val_accuracy: 0.7477 - val_loss: 0.7338\nEpoch 18/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.1969 - val_accuracy: 0.7387 - val_loss: 0.8247\nEpoch 19/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.1997 - val_accuracy: 0.7387 - val_loss: 0.7102\nEpoch 20/20\n\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.1631 - val_accuracy: 0.7387 - val_loss: 0.8608\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Predict on the validation data\ny_pred = model.predict(\n    [X_test_vid_f, X_test_aud_f, X_test_text_f],  # Validation inputs\n    batch_size=32\n)\n\ny_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:46:43.868031Z","iopub.execute_input":"2025-03-10T00:46:43.868339Z","iopub.status.idle":"2025-03-10T00:46:44.401101Z","shell.execute_reply.started":"2025-03-10T00:46:43.868315Z","shell.execute_reply":"2025-03-10T00:46:44.400451Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n","output_type":"stream"},{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"array([[3.13532189e-04, 2.78350606e-04, 9.99324322e-01, 8.37712723e-05],\n       [5.12951287e-04, 1.86466903e-03, 9.97469902e-01, 1.52519235e-04],\n       [1.18484558e-03, 2.79903738e-03, 9.95824695e-01, 1.91417697e-04],\n       [3.08576357e-02, 9.67007041e-01, 1.50043098e-03, 6.34962344e-04],\n       [9.80149686e-01, 9.60831717e-03, 9.55630559e-03, 6.85692183e-04],\n       [5.19757390e-01, 4.50256199e-01, 2.90307403e-02, 9.55679687e-04],\n       [8.19563448e-01, 1.67756572e-01, 2.09472934e-03, 1.05852140e-02],\n       [2.47134879e-01, 7.44466841e-01, 4.12630988e-03, 4.27193055e-03],\n       [9.94552672e-01, 3.34860262e-04, 5.05749043e-03, 5.49826837e-05],\n       [4.59366740e-04, 8.28605890e-03, 5.94025223e-05, 9.91195202e-01],\n       [6.84748357e-03, 9.86105382e-01, 1.92445208e-04, 6.85469666e-03],\n       [5.43215811e-01, 1.69818420e-02, 4.39222604e-01, 5.79698943e-04],\n       [3.96015584e-01, 1.06070846e-01, 4.95449424e-01, 2.46418966e-03],\n       [1.26211846e-04, 2.61061738e-04, 9.99564111e-01, 4.86491226e-05],\n       [1.21047229e-01, 8.17315221e-01, 6.04508072e-02, 1.18674675e-03],\n       [3.38067226e-02, 6.81626379e-01, 2.83673048e-01, 8.93807563e-04],\n       [6.40322745e-01, 2.87336349e-01, 7.17289075e-02, 6.12020143e-04],\n       [5.19729976e-04, 9.98764634e-01, 2.08445257e-04, 5.07205783e-04],\n       [1.85892656e-02, 9.77234125e-01, 2.41921726e-03, 1.75749278e-03],\n       [9.24883527e-04, 1.35805560e-04, 6.57384517e-04, 9.98281956e-01],\n       [3.83532047e-01, 6.12429440e-01, 1.87500718e-03, 2.16346770e-03],\n       [3.62216786e-04, 8.31827230e-04, 9.98720288e-01, 8.57083869e-05],\n       [5.72517104e-02, 1.09898094e-02, 9.29873288e-01, 1.88526628e-03],\n       [9.95293438e-01, 2.31782044e-03, 2.16445420e-03, 2.24194446e-04],\n       [1.45487697e-03, 9.97763395e-01, 2.45515748e-05, 7.57141330e-04],\n       [9.99552429e-01, 1.81047319e-04, 2.40375433e-04, 2.61970144e-05],\n       [8.87391567e-02, 9.06432509e-01, 4.38658800e-03, 4.41763492e-04],\n       [3.87952401e-04, 8.72386561e-04, 9.98641670e-01, 9.79798788e-05],\n       [9.94025469e-01, 6.70851034e-04, 4.70627006e-03, 5.97437378e-04],\n       [1.42036438e-01, 8.36085439e-01, 2.13183109e-02, 5.59799431e-04],\n       [2.49937356e-01, 5.99730670e-01, 1.47330746e-01, 3.00125522e-03],\n       [3.08601320e-01, 5.41886330e-01, 1.48888350e-01, 6.24047883e-04],\n       [2.97684426e-04, 1.62296594e-04, 9.99433339e-01, 1.06556865e-04],\n       [9.95087802e-01, 2.16719985e-04, 4.66154795e-03, 3.38832215e-05],\n       [1.02309350e-04, 1.06346342e-04, 9.99746382e-01, 4.49772997e-05],\n       [9.99517441e-01, 1.03885497e-04, 3.43102438e-04, 3.54805161e-05],\n       [9.98653531e-01, 2.95425445e-04, 9.57889366e-04, 9.31688483e-05],\n       [1.32478133e-01, 7.78428733e-01, 8.89417529e-02, 1.51457556e-04],\n       [7.69440434e-04, 9.98251021e-01, 3.08139890e-04, 6.71362679e-04],\n       [2.36978100e-04, 1.82313772e-04, 1.29003092e-04, 9.99451697e-01],\n       [9.97816682e-01, 8.20395362e-04, 1.26487401e-03, 9.79646866e-05],\n       [6.23200741e-03, 5.48201567e-03, 9.88253593e-01, 3.24330322e-05],\n       [2.69276202e-01, 7.21181452e-01, 9.00932308e-03, 5.33008948e-04],\n       [1.96013212e-01, 3.29883397e-01, 4.72366899e-01, 1.73646514e-03],\n       [1.17977627e-01, 7.72308707e-01, 1.06057674e-01, 3.65593308e-03],\n       [4.04130289e-04, 2.83946749e-04, 5.60574445e-05, 9.99255836e-01],\n       [9.30702329e-01, 2.52956189e-02, 4.38581854e-02, 1.43881873e-04],\n       [3.31707567e-01, 6.65073693e-01, 1.75862655e-03, 1.46007596e-03],\n       [2.03785650e-03, 9.90753531e-01, 4.91753034e-03, 2.29109917e-03],\n       [9.92839932e-01, 6.62418269e-03, 4.17896546e-04, 1.17985765e-04],\n       [4.14516479e-01, 5.79988480e-01, 4.49523795e-03, 9.99846146e-04],\n       [5.07938268e-04, 9.97014284e-01, 3.22199427e-04, 2.15557148e-03],\n       [1.32648670e-03, 9.98238444e-01, 8.09037374e-05, 3.54195916e-04],\n       [5.60675740e-01, 9.49827582e-03, 4.12695527e-01, 1.71305165e-02],\n       [4.71425796e-04, 6.26448658e-04, 9.98740733e-01, 1.61386430e-04],\n       [9.94628966e-01, 3.34652723e-03, 1.84510427e-03, 1.79520284e-04],\n       [5.21419227e-01, 1.19994942e-03, 4.77250934e-01, 1.29856562e-04],\n       [2.83940453e-02, 9.70988750e-01, 4.65707126e-04, 1.51463129e-04],\n       [8.63007852e-04, 8.08990793e-04, 9.98148561e-01, 1.79458148e-04],\n       [3.11133510e-04, 8.50212891e-05, 7.83122232e-05, 9.99525547e-01],\n       [2.41666203e-04, 1.11898087e-04, 9.91608904e-05, 9.99547303e-01],\n       [9.70267177e-01, 2.85198838e-02, 2.75941944e-04, 9.36896657e-04],\n       [2.71885353e-03, 9.87844527e-01, 4.27720370e-03, 5.15942741e-03],\n       [3.07306461e-03, 9.95541513e-01, 2.62658199e-04, 1.12284708e-03],\n       [8.31087410e-01, 1.52077693e-02, 1.52724862e-01, 9.79993958e-04],\n       [1.64257002e-03, 9.97736216e-01, 8.71445154e-05, 5.34025254e-04],\n       [9.89442825e-01, 9.36625246e-03, 1.03196723e-03, 1.58927331e-04],\n       [3.51294205e-02, 9.63390172e-01, 1.34181662e-03, 1.38561954e-04],\n       [4.71239910e-04, 4.74847096e-04, 9.98940647e-01, 1.13338239e-04],\n       [4.75916743e-01, 9.67475399e-03, 5.14174044e-01, 2.34455045e-04],\n       [9.78253424e-01, 2.65252223e-04, 2.12189127e-02, 2.62493413e-04],\n       [9.70386118e-02, 8.63541126e-01, 3.84612940e-02, 9.58909630e-04],\n       [9.16363380e-04, 2.15199552e-02, 7.63544696e-04, 9.76800144e-01],\n       [3.04186732e-01, 4.01243478e-01, 2.94284463e-01, 2.85321032e-04],\n       [1.27740413e-01, 8.68814766e-01, 2.97356700e-03, 4.71223728e-04],\n       [1.59493415e-04, 1.26063125e-04, 6.09456729e-05, 9.99653459e-01],\n       [9.85495210e-01, 1.37430811e-02, 2.59355555e-04, 5.02375071e-04],\n       [9.99344647e-01, 1.62004479e-04, 4.58760391e-04, 3.45082080e-05],\n       [4.05805098e-04, 4.90922794e-05, 1.64402401e-04, 9.99380708e-01],\n       [9.04711662e-04, 4.54568653e-04, 2.33839426e-04, 9.98406947e-01],\n       [9.87961233e-01, 1.47782569e-03, 1.04923481e-02, 6.85006671e-05],\n       [9.60470617e-01, 1.04501029e-03, 2.31781043e-02, 1.53063387e-02],\n       [9.91290808e-01, 6.05240185e-03, 2.48380122e-03, 1.72910048e-04],\n       [2.93561548e-01, 3.33014689e-02, 6.73095167e-01, 4.18218879e-05],\n       [9.97726738e-01, 1.38779066e-03, 8.89404400e-05, 7.96456356e-04],\n       [7.64647052e-02, 9.19925988e-01, 2.81792786e-03, 7.91445840e-04],\n       [3.11353058e-01, 3.80810946e-01, 3.07454646e-01, 3.81324615e-04],\n       [1.19753357e-03, 9.98463631e-01, 3.98017110e-05, 2.99112435e-04],\n       [1.88788131e-01, 7.82874227e-01, 2.75736433e-02, 7.63995748e-04],\n       [6.68567717e-01, 6.68552220e-02, 1.42258868e-01, 1.22318186e-01],\n       [9.70860004e-01, 1.91217317e-04, 2.82780174e-02, 6.70835027e-04],\n       [1.32417795e-03, 3.67297558e-04, 9.98227417e-01, 8.10416022e-05],\n       [7.95475423e-01, 2.03300998e-01, 3.83646257e-04, 8.39967979e-04],\n       [5.82560198e-04, 5.24869305e-04, 9.98861194e-01, 3.13880810e-05],\n       [1.67527131e-03, 9.86225724e-01, 1.15357880e-02, 5.63269015e-04],\n       [5.27250469e-01, 7.77136628e-03, 4.60580021e-01, 4.39813500e-03],\n       [4.52090637e-04, 9.99264300e-01, 5.10574755e-05, 2.32500126e-04],\n       [9.42522347e-01, 5.07000238e-02, 1.62012025e-03, 5.15761646e-03],\n       [9.59728181e-01, 3.58559079e-02, 1.83190219e-03, 2.58402177e-03],\n       [1.08806558e-01, 8.77870381e-01, 1.28904758e-02, 4.32584086e-04],\n       [9.41319883e-01, 4.05473001e-02, 1.79749392e-02, 1.57921721e-04],\n       [9.97462869e-01, 9.79497097e-04, 1.52886694e-03, 2.86856975e-05],\n       [3.30125242e-02, 9.62266684e-01, 1.12052367e-03, 3.60017619e-03],\n       [6.97126519e-03, 1.04853977e-02, 9.82447565e-01, 9.57767261e-05],\n       [6.86591685e-01, 2.89503753e-01, 2.37524454e-02, 1.52139575e-04],\n       [1.99563685e-04, 1.96718160e-04, 9.99561965e-01, 4.17006158e-05],\n       [2.55411374e-04, 9.98800397e-01, 5.41522459e-04, 4.02636681e-04],\n       [8.93426061e-01, 2.51758620e-02, 7.88721964e-02, 2.52587767e-03],\n       [5.13928884e-04, 5.09679317e-04, 6.33805394e-05, 9.98913050e-01],\n       [1.54265538e-01, 1.10149076e-02, 8.34607244e-01, 1.12305337e-04],\n       [9.98793125e-01, 1.06350938e-03, 3.76823518e-05, 1.05766369e-04],\n       [3.72424126e-02, 3.52710159e-03, 9.59155262e-01, 7.51404950e-05]],\n      dtype=float32)"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"# If the model's output is probabilities, get the class with the highest probability\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_pred_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:46:53.232818Z","iopub.execute_input":"2025-03-10T00:46:53.233131Z","iopub.status.idle":"2025-03-10T00:46:53.238668Z","shell.execute_reply.started":"2025-03-10T00:46:53.233103Z","shell.execute_reply":"2025-03-10T00:46:53.237893Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"array([2, 2, 2, 1, 0, 0, 0, 1, 0, 3, 1, 0, 2, 2, 1, 1, 0, 1, 1, 3, 1, 2,\n       2, 0, 1, 0, 1, 2, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 1, 3, 0, 2, 1, 2,\n       1, 3, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 1, 2, 3, 3, 0, 1, 1, 0, 1,\n       0, 1, 2, 2, 0, 1, 3, 1, 1, 3, 0, 0, 3, 3, 0, 0, 0, 2, 0, 1, 1, 1,\n       1, 0, 0, 2, 0, 2, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2, 0, 2, 1, 0, 3, 2,\n       0, 2])"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"# Display classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred_classes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:46:56.479369Z","iopub.execute_input":"2025-03-10T00:46:56.479663Z","iopub.status.idle":"2025-03-10T00:46:56.491729Z","shell.execute_reply.started":"2025-03-10T00:46:56.479642Z","shell.execute_reply":"2025-03-10T00:46:56.490866Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.77      0.77      0.77        39\n           1       0.77      0.79      0.78        38\n           2       0.74      0.74      0.74        23\n           3       1.00      0.92      0.96        12\n\n    accuracy                           0.79       112\n   macro avg       0.82      0.80      0.81       112\nweighted avg       0.79      0.79      0.79       112\n\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"# Compute confusion matrix\ncm = confusion_matrix(y_test, y_pred_classes)\n\n# Plot confusion matrix using seaborn\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2, 3], yticklabels=[0, 1, 2, 3])\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T00:47:09.893776Z","iopub.execute_input":"2025-03-10T00:47:09.894082Z","iopub.status.idle":"2025-03-10T00:47:10.124487Z","shell.execute_reply.started":"2025-03-10T00:47:09.894057Z","shell.execute_reply":"2025-03-10T00:47:10.123630Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAoAAAAIjCAYAAACTRapjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABE8UlEQVR4nO3deVhUdf//8deAMqCyCAhoKm6J+5KWobndmWabpmZmJZpZGVpJmtGdKbZgm9riUneF5nJnm9qqmd5qFppZ5JIbLlkpqKggCAPB/P7oK78mNcEYDs7n+bivc13NOWfOeQ9zXd3vXp/P+YzN6XQ6BQAAAGN4WV0AAAAAyhcNIAAAgGFoAAEAAAxDAwgAAGAYGkAAAADD0AACAAAYhgYQAADAMDSAAAAAhqEBBAAAMAwNIIC/tXv3bvXs2VOBgYGy2WxasmRJmV5///79stlsmjNnTple92LWrVs3devWzeoyAHgwGkDgIrBnzx7de++9atCggXx9fRUQEKBOnTrppZdeUm5urlvvHRMToy1btujpp5/WvHnz1L59e7ferzwNHTpUNptNAQEBZ/077t69WzabTTabTS+88EKpr3/w4EFNmjRJKSkpZVAtAJSdSlYXAODvffrpp7rllltkt9s1ZMgQtWjRQvn5+Vq3bp3GjRunbdu26fXXX3fLvXNzc5WcnKx///vfGjVqlFvuERkZqdzcXFWuXNkt1z+fSpUq6dSpU/r44481cOBAl2MLFiyQr6+v8vLyLujaBw8eVEJCgurVq6c2bdqU+H1ffPHFBd0PAEqKBhCowPbt26dBgwYpMjJSq1atUs2aNYuPxcbGKjU1VZ9++qnb7n/kyBFJUlBQkNvuYbPZ5Ovr67brn4/dblenTp303//+94wGcOHChbr++uv1wQcflEstp06dUpUqVeTj41Mu9wNgLoaAgQrsueeeU3Z2tt58802X5u+0Ro0a6cEHHyx+/fvvv+vJJ59Uw4YNZbfbVa9ePT322GNyOBwu76tXr55uuOEGrVu3TldccYV8fX3VoEEDvf3228XnTJo0SZGRkZKkcePGyWazqV69epL+GDo9/c9/NmnSJNlsNpd9K1as0FVXXaWgoCBVq1ZNUVFReuyxx4qPn2sO4KpVq9S5c2dVrVpVQUFB6tOnj7Zv337W+6Wmpmro0KEKCgpSYGCghg0bplOnTp37D/sXgwcP1ueff64TJ04U79u4caN2796twYMHn3H+sWPHNHbsWLVs2VLVqlVTQECAevfurR9//LH4nNWrV+vyyy+XJA0bNqx4KPn05+zWrZtatGihTZs2qUuXLqpSpUrx3+WvcwBjYmLk6+t7xufv1auXqlevroMHD5b4swKARAMIVGgff/yxGjRooI4dO5bo/LvvvltPPPGELrvsMk2bNk1du3ZVYmKiBg0adMa5qampGjBggK655hq9+OKLql69uoYOHapt27ZJkvr166dp06ZJkm677TbNmzdP06dPL1X927Zt0w033CCHw6HJkyfrxRdf1E033aSvv/76b9/35ZdfqlevXjp8+LAmTZqkuLg4ffPNN+rUqZP2799/xvkDBw7UyZMnlZiYqIEDB2rOnDlKSEgocZ39+vWTzWbThx9+WLxv4cKFatKkiS677LIzzt+7d6+WLFmiG264QVOnTtW4ceO0ZcsWde3atbgZa9q0qSZPnixJuueeezRv3jzNmzdPXbp0Kb5ORkaGevfurTZt2mj69Onq3r37Wet76aWXVKNGDcXExKiwsFCS9Nprr+mLL77QK6+8olq1apX4swKAJMkJoELKzMx0SnL26dOnROenpKQ4JTnvvvtul/1jx451SnKuWrWqeF9kZKRTknPt2rXF+w4fPuy02+3Ohx9+uHjfvn37nJKczz//vMs1Y2JinJGRkWfUMHHiROef/7Uybdo0pyTnkSNHzln36XskJSUV72vTpo0zLCzMmZGRUbzvxx9/dHp5eTmHDBlyxv3uuusul2vefPPNzpCQkHPe88+fo2rVqk6n0+kcMGCA8+qrr3Y6nU5nYWGhMyIiwpmQkHDWv0FeXp6zsLDwjM9ht9udkydPLt63cePGMz7baV27dnVKcs6ePfusx7p27eqyb/ny5U5Jzqeeesq5d+9eZ7Vq1Zx9+/Y972cEgLMhAQQqqKysLEmSv79/ic7/7LPPJElxcXEu+x9++GFJOmOuYLNmzdS5c+fi1zVq1FBUVJT27t17wTX/1em5g0uXLlVRUVGJ3nPo0CGlpKRo6NChCg4OLt7fqlUrXXPNNcWf88/uu+8+l9edO3dWRkZG8d+wJAYPHqzVq1crLS1Nq1atUlpa2lmHf6U/5g16ef3xr8/CwkJlZGQUD29///33Jb6n3W7XsGHDSnRuz549de+992ry5Mnq16+ffH199dprr5X4XgDwZzSAQAUVEBAgSTp58mSJzv/555/l5eWlRo0aueyPiIhQUFCQfv75Z5f9devWPeMa1atX1/Hjxy+w4jPdeuut6tSpk+6++26Fh4dr0KBBevfdd/+2GTxdZ1RU1BnHmjZtqqNHjyonJ8dl/18/S/Xq1SWpVJ/luuuuk7+/vxYtWqQFCxbo8ssvP+NveVpRUZGmTZumSy+9VHa7XaGhoapRo4Y2b96szMzMEt/zkksuKdUDHy+88IKCg4OVkpKil19+WWFhYSV+LwD8GQ0gUEEFBASoVq1a2rp1a6ne99eHMM7F29v7rPudTucF3+P0/LTT/Pz8tHbtWn355Ze68847tXnzZt1666265pprzjj3n/gnn+U0u92ufv36ae7cuVq8ePE50z9JeuaZZxQXF6cuXbpo/vz5Wr58uVasWKHmzZuXOOmU/vj7lMYPP/ygw4cPS5K2bNlSqvcCwJ/RAAIV2A033KA9e/YoOTn5vOdGRkaqqKhIu3fvdtmfnp6uEydOFD/RWxaqV6/u8sTsaX9NGSXJy8tLV199taZOnaqffvpJTz/9tFatWqX//e9/Z7326Tp37tx5xrEdO3YoNDRUVatW/Wcf4BwGDx6sH374QSdPnjzrgzOnvf/+++revbvefPNNDRo0SD179lSPHj3O+JuUtBkviZycHA0bNkzNmjXTPffco+eee04bN24ss+sDMAsNIFCBPfLII6pataruvvtupaenn3F8z549eumllyT9MYQp6YwndadOnSpJuv7668usroYNGyozM1ObN28u3nfo0CEtXrzY5bxjx46d8d7TCyL/dWma02rWrKk2bdpo7ty5Lg3V1q1b9cUXXxR/Tnfo3r27nnzySb366quKiIg453ne3t5npIvvvfeefvvtN5d9pxvVszXLpTV+/HgdOHBAc+fO1dSpU1WvXj3FxMSc8+8IAH+HhaCBCqxhw4ZauHChbr31VjVt2tTll0C++eYbvffeexo6dKgkqXXr1oqJidHrr7+uEydOqGvXrvr22281d+5c9e3b95xLjFyIQYMGafz48br55pv1wAMP6NSpU5o1a5YaN27s8hDE5MmTtXbtWl1//fWKjIzU4cOHNXPmTNWuXVtXXXXVOa///PPPq3fv3oqOjtbw4cOVm5urV155RYGBgZo0aVKZfY6/8vLy0uOPP37e82644QZNnjxZw4YNU8eOHbVlyxYtWLBADRo0cDmvYcOGCgoK0uzZs+Xv76+qVauqQ4cOql+/fqnqWrVqlWbOnKmJEycWL0uTlJSkbt26acKECXruuedKdT0AYBkY4CKwa9cu54gRI5z16tVz+vj4OP39/Z2dOnVyvvLKK868vLzi8woKCpwJCQnO+vXrOytXruysU6eOMz4+3uUcp/OPZWCuv/76M+7z1+VHzrUMjNPpdH7xxRfOFi1aOH18fJxRUVHO+fPnn7EMzMqVK519+vRx1qpVy+nj4+OsVauW87bbbnPu2rXrjHv8damUL7/80tmpUyenn5+fMyAgwHnjjTc6f/rpJ5dzTt/vr8vMJCUlOSU59+3bd86/qdPpugzMuZxrGZiHH37YWbNmTaefn5+zU6dOzuTk5LMu37J06VJns2bNnJUqVXL5nF27dnU2b978rPf883WysrKckZGRzssuu8xZUFDgct6YMWOcXl5ezuTk5L/9DADwVzansxSzpAEAAHDRYw4gAACAYWgAAQAADEMDCAAAYBgaQAAAgApi1qxZatWqlQICAhQQEKDo6Gh9/vnnxcfz8vIUGxurkJAQVatWTf379z/rMmHnw0MgAAAAFcTHH38sb29vXXrppXI6nZo7d66ef/55/fDDD2revLlGjhypTz/9VHPmzFFgYKBGjRolLy8vff3116W6Dw0gAABABRYcHKznn39eAwYMUI0aNbRw4UINGDBA0h+/kNS0aVMlJyfryiuvLPE1GQIGAABwI4fDoaysLJetJL/iU1hYqHfeeUc5OTmKjo7Wpk2bVFBQoB49ehSf06RJE9WtW7dEPxn6Zx75SyB+bUdZXQLK0fqliVaXgHIU4m+3ugSUo1B/H6tLQDnytbArcWfvML5PqBISElz2TZw48Zy/bLRlyxZFR0crLy9P1apV0+LFi9WsWTOlpKTIx8dHQUFBLueHh4crLS2tVDV5ZAMIAABQUcTHxysuLs5ln91+7v+YjYqKUkpKijIzM/X+++8rJiZGa9asKdOaaAABAABs7psVZ7fb/7bh+ysfHx81atRIktSuXTtt3LhRL730km699Vbl5+frxIkTLilgenq6IiIiSlUTcwABAABsNvdt/1BRUZEcDofatWunypUra+XKlcXHdu7cqQMHDig6OrpU1yQBBAAAqCDi4+PVu3dv1a1bVydPntTChQu1evVqLV++XIGBgRo+fLji4uIUHBysgIAAjR49WtHR0aV6AliiAQQAAHDrEHBpHD58WEOGDNGhQ4cUGBioVq1aafny5brmmmskSdOmTZOXl5f69+8vh8OhXr16aebMmaW+j0euA8hTwGbhKWCz8BSwWXgK2CyWPgXcfozbrp373TS3XftCkQACAACUwVy9i0nFyDsBAABQbkgAAQAAKsgcwPJi1qcFAAAACSAAAIBpcwBpAAEAABgCBgAAgCcjAQQAADBsCJgEEAAAwDAkgAAAAMwBBAAAgCcjAQQAAGAOIAAAADwZCSAAAIBhcwBpAAEAABgCBgAAgCcjAQQAADBsCNisTwsAAAASQAAAABJAAAAAeDQSQAAAAC+eAgYAAIAHIwEEAAAwbA4gDSAAAAALQQMAAMCTkQACAAAYNgRs1qcFAAAACSAAAABzAAEAAODRSAABAACYAwgAAABPRgIIAABg2BxAGkAAAACGgAEAAODJSAABAAAMGwImAQQAADAMCSAAAABzAAEAAODJSAABAACYAwgAAABPRgIIAABg2BxAGkAAAADDGkCzPi0AAABIAAEAAHgIBAAAAB6NBPAiM+KWqzRiQGdF1gqWJG3fm6ZnXv9cX3z9kyTJ7lNJU+L66ZZe7WT3qaQvk7frwWcW6fCxk1aWjTJ07OhhzX/jFaV8+40cjjxF1Kqt+8dOVMOoZlaXhjL20QeL9NGHi5R+6KAkKbJBQ915133q0LGzxZXBnd5ZuEBzk97U0aNH1DiqiR59bIJatmpldVmejzmAqMh+Sz+hCa8sVcfbn1On25/X6m936b1p96hpgwhJ0nNj++v6Li10+yNvqufd01WzRqDeefFui6tGWck+maUJDw1XJe9KeuyZlzTtjXc15N4xquofYHVpcIPQsHCNiH1Is+Ys0sw576htuw564pEHtH9vqtWlwU2Wff6ZXnguUffeH6t33lusqKgmGnnvcGVkZFhdGjwMCeBF5rO1W11eT5rxsUbccpWuaFVfvx0+oaF9ozX0sTlas3GXJOmeifP14+IJuqJlPX27Zb8FFaMsLV00VyE1wnX/uInF+8JqXmJhRXCnjp27ubwePvIBfbx4kX7auln1GjSypii41by5Seo3YKD63txfkvT4xAStXbtaSz78QMNH3GNxdR7OsDmAljaAR48e1VtvvaXk5GSlpaVJkiIiItSxY0cNHTpUNWrUsLK8Cs/Ly6b+11ymqn4+2rB5n9o2rSufypW0av3O4nN27U/XgUPH1KFVfRpAD/Bd8lq1bn+lpk4er5+2fK/gkBrqedMt6nHdzVaXBjcrLCzUmlVfKC83V81atra6HLhBQX6+tv+0TcNH3Fu8z8vLS1de2VGbf/zBwsrgiSxrADdu3KhevXqpSpUq6tGjhxo3bixJSk9P18svv6wpU6Zo+fLlat++/d9ex+FwyOFwuOxzFhXK5uXtttqt1rxRLa2e+7B8fSopO9ehWx/+j3bsTVPrxrXlyC9QZnauy/mHM7IUHsIQoSc4fOg3rfj4A13f/3bdPHiY9uz8SUkzXlClSpXVrecNVpcHN9ibukujR9yh/Px8+flVUcKz01WvfkOry4IbHD9xXIWFhQoJCXHZHxISon379lpUlUEMmwNoWQM4evRo3XLLLZo9e7Zsf4ldnU6n7rvvPo0ePVrJycl/e53ExEQlJCS47PMOv1yVa15R5jVXFLv2p6vDoEQFVvPTzT3a6j+T71TPu1+yuiyUgyJnkRo2bqbBw2MlSfUbNdGB/Xu04pMPaAA9VJ3I+nr97feVk3NSa1et0LOTH9fUWUk0gUBZM2wI2LJ298cff9SYMWPOaP4kyWazacyYMUpJSTnvdeLj45WZmemyVQpv54aKK46C3wu195ej+mH7L3rilY+0Zddvir2tm9IysmT3qazAan4u54eFBCg9I8uialGWqgeHqnbd+i77atetr6OH0yyqCO5WuXJlXVKnrho3aa67739IDRs11oeL5ltdFtygelB1eXt7n/HAR0ZGhkJDQy2qCp7KsgYwIiJC33777TmPf/vttwoPDz/vdex2uwICAlw2Tx7+PRsvm012n0r6YfsB5Rf8ru4dooqPXRoZpro1g7Vh8z4LK0RZiWreWgd//dll38Fff1aN8JoWVYTyVuR0qiA/3+oy4AaVfXzUtFlzbVj//0e+ioqKtGFDslq1bmthZWaw2Wxu2yoiy4aAx44dq3vuuUebNm3S1VdfXdzspaena+XKlfrPf/6jF154waryKqzJo2/S8q+36ZdDx+Vf1Ve39m6vLu0v1Y33z1RWdp7mLEnWsw/307HMHJ3MydPU8bdo/Y97eQDEQ1zff7AmPHiXPlz4ljp2vUapO7dp5WeLdc9D/7a6NLjBGzOn64roqxQWXlOnTuVo1Ref6cfvN2rK9NlWlwY3uTNmmCY8Nl7Nm7dQi5atNH/eXOXm5qrvzf2sLg0exrIGMDY2VqGhoZo2bZpmzpypwsJCSZK3t7fatWunOXPmaODAgVaVV2HVCK6mN58coojQAGVm52nr7t904/0ztWrDDknSIy98oKIip/77wt1/LAT9zXY9mLjI4qpRVhpFNdfYSS9o4Zuv6oP5bygsopZiRj6szlf3tro0uMHx48c0JeHfOpZxRFWr+atBw0s1Zfpste/Q0erS4CbX9r5Ox48d08xXX9bRo0cU1aSpZr72hkIYAna7iprUuYvN6XQ6rS6ioKBAR48elSSFhoaqcuXK/+h6fm1HlUVZuEisX5podQkoRyH+dqtLQDkK9fexugSUI18LF6erOiDJbdfOeX+Y2659oSrEQtCVK1dWzZrMYQIAABYxKwDkp+AAAABMUyESQAAAACuZNgeQBhAAABjPtAaQIWAAAADDkAACAADjkQACAADAo5EAAgAA45EAAgAAwKORAAIAAJgVAJIAAgAAVBSJiYm6/PLL5e/vr7CwMPXt21c7d+50Oadbt26y2Wwu23333Veq+9AAAgAA4/21oSrLrTTWrFmj2NhYrV+/XitWrFBBQYF69uypnJwcl/NGjBihQ4cOFW/PPfdcqe7DEDAAAEAFsWzZMpfXc+bMUVhYmDZt2qQuXboU769SpYoiIiIu+D4kgAAAwHjuTAAdDoeysrJcNofDUaK6MjMzJUnBwcEu+xcsWKDQ0FC1aNFC8fHxOnXqVKk+Lw0gAAAwnjsbwMTERAUGBrpsiYmJ562pqKhIDz30kDp16qQWLVoU7x88eLDmz5+v//3vf4qPj9e8efN0xx13lOrzMgQMAADgRvHx8YqLi3PZZ7fbz/u+2NhYbd26VevWrXPZf8899xT/c8uWLVWzZk1dffXV2rNnjxo2bFiimmgAAQCA8dy5ELTdbi9Rw/dno0aN0ieffKK1a9eqdu3af3tuhw4dJEmpqak0gAAAABcbp9Op0aNHa/HixVq9erXq169/3vekpKRIkmrWrFni+9AAAgAAVJCFoGNjY7Vw4UItXbpU/v7+SktLkyQFBgbKz89Pe/bs0cKFC3XdddcpJCREmzdv1pgxY9SlSxe1atWqxPehAQQAAKggZs2aJemPxZ7/LCkpSUOHDpWPj4++/PJLTZ8+XTk5OapTp4769++vxx9/vFT3oQEEAADGc+ccwNJwOp1/e7xOnTpas2bNP74Py8AAAAAYhgQQAAAYr6IkgOWFBhAAABjPtAaQIWAAAADDkAACAACYFQCSAAIAAJiGBBAAABiPOYAAAADwaCSAAADAeCSAAAAA8GgkgAAAwHimJYA0gAAAwHimNYAMAQMAABiGBBAAAMCsAJAEEAAAwDQkgAAAwHjMAQQAAIBHIwEEAADGIwEEAACARyMBBAAAxjMtAaQBBAAAMKv/YwgYAADANCSAAADAeKYNAZMAAgAAGIYEEAAAGI8EEAAAAB6NBBAAABiPBBAAAAAejQQQAAAYz7QEkAYQAADArP6PIWAAAADTeGQC+P1nz1pdAsrRZdeNt7oElKPdq6ZaXQIAD2TaEDAJIAAAgGE8MgEEAAAoDRJAAAAAeDQSQAAAYDzDAkASQAAAANOQAAIAAOOZNgeQBhAAABjPsP6PIWAAAADTkAACAADjmTYETAIIAABgGBJAAABgPMMCQBJAAAAA05AAAgAA43l5mRUBkgACAAAYhgQQAAAYz7Q5gDSAAADAeCwDAwAAAI9GAggAAIxnWABIAggAAGAaEkAAAGA85gACAADAo5EAAgAA45EAAgAAwKORAAIAAOMZFgDSAAIAADAEDAAAAI9GAggAAIxnWABIAggAAGAaEkAAAGA85gACAADAo5EAAgAA4xkWAJIAAgAAmIYEEAAAGI85gAAAAPBoNIAAAMB4Npv7ttJITEzU5ZdfLn9/f4WFhalv377auXOnyzl5eXmKjY1VSEiIqlWrpv79+ys9Pb1U96EBBAAAxrPZbG7bSmPNmjWKjY3V+vXrtWLFChUUFKhnz57KyckpPmfMmDH6+OOP9d5772nNmjU6ePCg+vXrV6r7MAcQAACggli2bJnL6zlz5igsLEybNm1Sly5dlJmZqTfffFMLFy7Uv/71L0lSUlKSmjZtqvXr1+vKK68s0X1oAAEAgPHc+QyIw+GQw+Fw2We322W328/73szMTElScHCwJGnTpk0qKChQjx49is9p0qSJ6tatq+Tk5BI3gAwBAwAAuFFiYqICAwNdtsTExPO+r6ioSA899JA6deqkFi1aSJLS0tLk4+OjoKAgl3PDw8OVlpZW4ppIAAEAgPHcuQxMfHy84uLiXPaVJP2LjY3V1q1btW7dujKviQYQAADAjUo63Ptno0aN0ieffKK1a9eqdu3axfsjIiKUn5+vEydOuKSA6enpioiIKPH1GQIGAADGqyjLwDidTo0aNUqLFy/WqlWrVL9+fZfj7dq1U+XKlbVy5crifTt37tSBAwcUHR1d4vuQAAIAAFQQsbGxWrhwoZYuXSp/f//ieX2BgYHy8/NTYGCghg8frri4OAUHBysgIECjR49WdHR0iR8AkWgAAQAAKsxPwc2aNUuS1K1bN5f9SUlJGjp0qCRp2rRp8vLyUv/+/eVwONSrVy/NnDmzVPehAQQAAMarIP2fnE7nec/x9fXVjBkzNGPGjAu+D3MAAQAADEMCCAAAjFdRhoDLCwkgAACAYUgAAQCA8UgAAQAA4NFIAAEAgPEMCwBJAAEAAExDAniR+2/SbC2a+7rLvkvq1NOMeR9aVBHK0ohbrtKIAZ0VWStYkrR9b5qeef1zffH1T5Iku08lTYnrp1t6tZPdp5K+TN6uB59ZpMPHTlpZNsrIRx8s0kcfLlL6oYOSpMgGDXXnXfepQ8fOFlcGd3pn4QLNTXpTR48eUeOoJnr0sQlq2aqV1WV5PNPmANIAeoC69Roq4cVZxa+9vb0trAZl6bf0E5rwylKlHjgim2y648YOem/aPbpy0BRt35um58b2V++rmuv2R95UVnaupj06UO+8eLf+NWya1aWjDISGhWtE7EO6pHaknHLqi08/0hOPPKDX3n5P9Ro0sro8uMGyzz/TC88l6vGJCWrZsrUWzJurkfcO19JPlikkJMTq8jyaYf0fQ8CewMvbW9VDQou3gKDqVpeEMvLZ2q1avu4n7TlwRKkHDmvSjI+VfcqhK1rVV0A1Xw3tG63xUz/Umo279MP2X3TPxPmKbtNQV7SsZ3XpKAMdO3dTh45dVLtupOrUrafhIx+QX5Uq+mnrZqtLg5vMm5ukfgMGqu/N/dWwUSM9PjFBvr6+WvLhB1aXBg9DA+gBDv12QMP699S9t92oqU/9W0fSD1ldEtzAy8umW3q1U1U/H23YvE9tm9aVT+VKWrV+Z/E5u/an68ChY+rQqr6FlcIdCgsLtWrF58rLzVWzlq2tLgduUJCfr+0/bdOV0R2L93l5eenKKztq848/WFiZGWw2m9u2iqhCDwH/8ssvmjhxot56661znuNwOORwOFz25Tt+l4/d7u7yKoTGzVrqgUcTdEmdSB3POKp35r6uxx4YrpeT3pNflapWl4cy0LxRLa2e+7B8fSopO9ehWx/+j3bsTVPrxrXlyC9QZnauy/mHM7IUHhJgUbUoa3tTd2n0iDuUn58vP78qSnh2uurVb2h1WXCD4yeOq7Cw8Iyh3pCQEO3bt9eiquCpKnQCeOzYMc2dO/dvz0lMTFRgYKDL9vorL5RThdZr16GTOnW7RvUaNlbbKzpqwpRXlJOdrXX/W2F1aSgju/anq8OgRHUZ8oL+8946/WfynWrSIMLqslBO6kTW1+tvv68Zby7QTf0G6tnJj2v/vj1WlwV4HJvNfVtFZGkC+NFHH/3t8b17z/9fPPHx8YqLi3PZt+/Y7/+orotZNX9/1apdV2m//WJ1KSgjBb8Xau8vRyVJP2z/Re2a11Xsbd30/hffy+5TWYHV/FxSwLCQAKVnZFlVLspY5cqVdUmdupKkxk2aa+dPW/XhovmKe3SixZWhrFUPqi5vb29lZGS47M/IyFBoaKhFVcFTWdoA9u3bVzabTU6n85znnG/s3G63y/6X4V6fnJwyqe9ilHvqlNIO/qpuPa+3uhS4iZfNJrtPJf2w/YDyC35X9w5RWrIyRZJ0aWSY6tYM1obN+6wtEm5T5HSqID/f6jLgBpV9fNS0WXNtWJ+sf13dQ5JUVFSkDRuSNei2OyyuzvN5VdSozk0sbQBr1qypmTNnqk+fPmc9npKSonbt2pVzVReXpJnTdHnHLqoRXlPHM47ov0mz5eXlpc5XX2t1aSgDk0ffpOVfb9Mvh47Lv6qvbu3dXl3aX6ob75+prOw8zVmSrGcf7qdjmTk6mZOnqeNv0fof9+rbLfutLh1l4I2Z03VF9FUKC6+pU6dytOqLz/Tj9xs1Zfpsq0uDm9wZM0wTHhuv5s1bqEXLVpo/b65yc3PV9+Z+VpcGD2NpA9iuXTtt2rTpnA3g+dJBSBlH0vXik/E6mZWpwMDqatqyjZ6dOVeBLAXjEWoEV9ObTw5RRGiAMrPztHX3b7rx/platWGHJOmRFz5QUZFT/33h7j8Wgv5mux5MXGRx1Sgrx48f05SEf+tYxhFVreavBg0v1ZTps9W+Q8fzvxkXpWt7X6fjx45p5qsv6+jRI4pq0lQzX3tDIQwBu51hAaBsTgs7rK+++ko5OTm69tqzp1U5OTn67rvv1LVr11Jdd/shc4eATXTZdeOtLgHlaPeqqVaXgHIU6u9jdQkoR74WxlK9Zm5w27WX39/Bbde+UJYmgJ07//3PGVWtWrXUzR8AAAD+XoVeBxAAAKA8eBk2BFyh1wEEAABA2SMBBAAAxquoP9nmLiSAAAAAhiEBBAAAxjMsACQBBAAAMA0JIAAAMJ5NZkWANIAAAMB4LAMDAAAAj0YCCAAAjMcyMAAAAPBoJIAAAMB4hgWAJIAAAACmIQEEAADG8zIsAiQBBAAAMAwJIAAAMJ5hASANIAAAAMvAAAAAwKORAAIAAOMZFgCSAAIAAJiGBBAAABiPZWAAAADg0UgAAQCA8czK/0gAAQAAjEMCCAAAjGfaOoA0gAAAwHheZvV/DAEDAACYhgQQAAAYz7QhYBJAAAAAw5AAAgAA4xkWAJIAAgAAmIYEEAAAGI85gAAAAPBoJIAAAMB4pq0DSAMIAACMxxAwAAAAPBoJIAAAMJ5Z+R8JIAAAgHEuqAH86quvdMcddyg6Olq//fabJGnevHlat25dmRYHAABQHrxsNrdtFVGpG8APPvhAvXr1kp+fn3744Qc5HA5JUmZmpp555pkyLxAAAABlq9QN4FNPPaXZs2frP//5jypXrly8v1OnTvr+++/LtDgAAIDyYLO5b6uISt0A7ty5U126dDljf2BgoE6cOFEWNQEAAMCNSt0ARkREKDU19Yz969atU4MGDcqkKAAAgPJks9nctlVEpW4AR4wYoQcffFAbNmyQzWbTwYMHtWDBAo0dO1YjR450R40AAAAoQ6VeB/DRRx9VUVGRrr76ap06dUpdunSR3W7X2LFjNXr0aHfUCAAA4FYVNKhzm1I3gDabTf/+9781btw4paamKjs7W82aNVO1atXcUR8AAIDbVdTlWtzlgn8JxMfHR82aNSvLWgAAAFAOSt0Adu/e/W8nNK5ateofFQQAAFDeKlIAuHbtWj3//PPatGmTDh06pMWLF6tv377Fx4cOHaq5c+e6vKdXr15atmxZie9R6gawTZs2Lq8LCgqUkpKirVu3KiYmprSXAwAAwJ/k5OSodevWuuuuu9SvX7+znnPttdcqKSmp+LXdbi/VPUrdAE6bNu2s+ydNmqTs7OzSXg4AAMByFWm5lt69e6t3795/e47dbldERMQF3+OCfgv4bO644w699dZbZXU5AAAAj+BwOJSVleWynf4p3Qu1evVqhYWFKSoqSiNHjlRGRkap3n/BD4H8VXJysnx9fcvqcv+Iv2/l858Ej7F71VSrS0A5GrN0q9UloBzNu+Myq0uAIcosETuLxMREJSQkuOybOHGiJk2adEHXu/baa9WvXz/Vr19fe/bs0WOPPabevXsrOTlZ3t7eJbpGqRvAv45FO51OHTp0SN99950mTJhQ2ssBAAB4tPj4eMXFxbnsK+2cvT8bNGhQ8T+3bNlSrVq1UsOGDbV69WpdffXVJbpGqRvAwMBAl9deXl6KiorS5MmT1bNnz9JeDgAAwHLunANot9v/UcN3Pg0aNFBoaKhSU1Pd0wAWFhZq2LBhatmypapXr35BRQIAAFQ0XhXnGZBS+/XXX5WRkaGaNWuW+D2lGvL29vZWz549deLEidLWBgAAgBLIzs5WSkqKUlJSJEn79u1TSkqKDhw4oOzsbI0bN07r16/X/v37tXLlSvXp00eNGjVSr169SnyPUs95bNGihfbu3VvatwEAAFRYXjb3baX13XffqW3btmrbtq0kKS4uTm3bttUTTzwhb29vbd68WTfddJMaN26s4cOHq127dvrqq69KNcxc6jmATz31lMaOHasnn3xS7dq1U9WqVV2OBwQElPaSAAAA+D/dunWT0+k85/Hly5f/43uUuAGcPHmyHn74YV133XWSpJtuusllwqTT6ZTNZlNhYeE/LgoAAKA8VaSFoMtDiRvAhIQE3Xffffrf//7nznoAAADgZiVuAE9HkV27dnVbMQAAAFa4mJ8CvhClegjEtHgUAADAE5XqIZDGjRuftwk8duzYPyoIAACgvJmWcZWqAUxISDjjl0AAAAAudl6GdYClagAHDRqksLAwd9UCAACAclDiBpD5fwAAwFOV+pcxLnIl/rx/tyAhAAAALh4lTgCLiorcWQcAAIBlTBvoNC3xBAAAMF6pfwsYAADA05j2FDAJIAAAgGFIAAEAgPEMCwBpAAEAAPgtYAAAAHg0EkAAAGA8HgIBAACARyMBBAAAxjMsACQBBAAAMA0JIAAAMB5PAQMAAMCjkQACAADj2WRWBEgDCAAAjMcQMAAAADwaCSAAADAeCSAAAAA8GgkgAAAwns2wlaBJAAEAAAxDAggAAIzHHEAAAAB4NBJAAABgPMOmANIAAgAAeBnWATIEDAAAYBgSQAAAYDweAgEAAIBHIwEEAADGM2wKIAkgAACAaUgAAQCA8bxkVgRIAggAAGAYEkAAAGA80+YA0gACAADjsQwMAAAAPBoJIAAAMB4/BQcAAACPRgJ4kfvog0X66MNFSj90UJIU2aCh7rzrPnXo2NniyuAOfN+erWl4Nd3UIlwNQvwUXMVHz63ao40HMouPvzf0srO+b97GX/XRtsPlVSbc7J2FCzQ36U0dPXpEjaOa6NHHJqhlq1ZWl+XxDAsAaQAvdqFh4RoR+5AuqR0pp5z64tOP9MQjD+i1t99TvQaNrC4PZYzv27PZK3np52On9L/dRzXuXw3POD5i0WaX120uCdDITpFa//OJcqoQ7rbs88/0wnOJenxiglq2bK0F8+Zq5L3DtfSTZQoJCbG6PHgQGsCLXMfO3VxeDx/5gD5evEg/bd1MQ+CB+L49W8pvWUr5Leucx0/k/u7y+vK6Qdp26KQOZ+e7uzSUk3lzk9RvwED1vbm/JOnxiQlau3a1lnz4gYaPuMfi6jwbcwBx0SosLNSqFZ8rLzdXzVq2trocuBnft9kCfSvpstqBWrU7w+pSUEYK8vO1/adtujK6Y/E+Ly8vXXllR23+8QcLK4MnsjwBzM3N1aZNmxQcHKxmzZq5HMvLy9O7776rIUOGnPP9DodDDofjL/tsstvtbqm3ItqbukujR9yh/Px8+flVUcKz01Wv/pnDR/AMfN+QpK6NQpRXUKgNB05YXQrKyPETx1VYWHjGUG9ISIj27dtrUVXmMCwAtDYB3LVrl5o2baouXbqoZcuW6tq1qw4dOlR8PDMzU8OGDfvbayQmJiowMNBlmzHtOXeXXqHUiayv199+XzPeXKCb+g3Us5Mf1/59e6wuC27C9w1J+telIfpq7zEVFDqtLgXwCF5u3CoiS+saP368WrRoocOHD2vnzp3y9/dXp06ddODAgRJfIz4+XpmZmS5b7JhH3Fh1xVO5cmVdUqeuGjdprrvvf0gNGzXWh4vmW10W3ITvG03CquqSQF+t3MXwryepHlRd3t7eyshw/V4zMjIUGhpqUVXwVJY2gN98840SExMVGhqqRo0a6eOPP1avXr3UuXNn7d1bsrjbbrcrICDAZTNp+PdsipxOFeQzKdwUfN/mubpxqPYczdHPx3OtLgVlqLKPj5o2a64N65OL9xUVFWnDhmS1at3WwsrMYLPZ3LZVRJY2gLm5uapU6f9PQ7TZbJo1a5ZuvPFGde3aVbt27bKwuovDGzOna/MP3ynt4G/am7pLb8ycrh+/36ire11vdWlwA75vz+ZbyUv1gv1UL9hPkhRWza56wX4KrVq5+By/yl66MjJIK3n4wyPdGTNMH77/rj5aslh79+zRU5MnKTc3V31v7md1afAwlj4E0qRJE3333Xdq2rSpy/5XX31VknTTTTdZUdZF5fjxY5qS8G8dyziiqtX81aDhpZoyfbbad+h4/jfjosP37dkahFZRwrWNi18PvaK2JGl1aoZmrPtZktSpfnXZbDZ9vfeYJTXCva7tfZ2OHzumma++rKNHjyiqSVPNfO0NhTAE7HYVM6dzH5vT6bRsBnFiYqK++uorffbZZ2c9fv/992v27NkqKioq1XV/Pc5wGOCpxizdanUJKEfz7jj7r5/AM/laGEu9/d0vbrv2kPZ13HbtC2VpA+guNICA56IBNAsNoFmsbADnb/rVbde+o11tt137QlXUp5MBAADgJpYvBA0AAGA10+YA0gACAADjVdDVWtyGIWAAAADDkAACAADjVdQFm92FBBAAAMAwJIAAAMB4piVipn1eAAAA45EAAgAA4zEHEAAAAJZZu3atbrzxRtWqVUs2m01LlixxOe50OvXEE0+oZs2a8vPzU48ePbR79+5S3YMGEAAAGM/mxq20cnJy1Lp1a82YMeOsx5977jm9/PLLmj17tjZs2KCqVauqV69eysvLK/E9GAIGAACoQHr37q3evXuf9ZjT6dT06dP1+OOPq0+fPpKkt99+W+Hh4VqyZIkGDRpUonuQAAIAAOPZbDa3bQ6HQ1lZWS6bw+G4oDr37duntLQ09ejRo3hfYGCgOnTooOTk5BJfhwYQAAAYz8uNW2JiogIDA122xMTEC6ozLS1NkhQeHu6yPzw8vPhYSTAEDAAA4Ebx8fGKi4tz2We32y2q5g80gAAAwHjuXAbGbreXWcMXEREhSUpPT1fNmjWL96enp6tNmzYlvg5DwAAAABeJ+vXrKyIiQitXrizel5WVpQ0bNig6OrrE1yEBBAAAxqtIy0BnZ2crNTW1+PW+ffuUkpKi4OBg1a1bVw899JCeeuopXXrppapfv74mTJigWrVqqW/fviW+Bw0gAABABfLdd9+pe/fuxa9Pzx+MiYnRnDlz9MgjjygnJ0f33HOPTpw4oauuukrLli2Tr69vie9hczqdzjKv3GK/Hs+3ugQAbjJm6VarS0A5mnfHZVaXgHLka2EstXRLyZ+gLa0+LSPcdu0LxRxAAAAAwzAEDAAAjOdVoWYBuh8NIAAAMJ4bV4GpkBgCBgAAMAwJIAAAMJ7NsCFgEkAAAADDkAACAADjMQcQAAAAHo0EEAAAGM+0ZWBIAAEAAAxDAggAAIxn2hxAGkAAAGA80xpAhoABAAAMQwIIAACMx0LQAAAA8GgkgAAAwHheZgWAJIAAAACmIQEEAADGYw4gAAAAPBoJIAAAMJ5p6wDSAAIAAOMxBAwAAACPRgIIAACMxzIwAAAA8GgkgAAAwHjMAQQAAIBHIwEEAADGM20ZGBJAAAAAw5AAAgAA4xkWANIAAgAAeBk2BswQMAAAgGFsTqfTaXURZS0rr8jqElCOfCrx3zGAp3o35RerS0A5GtK+jmX3Xp96wm3XvrJRkNuufaH4f04AAADDMAcQAADArCmAJIAAAACmIQEEAADG46fgAAAA4NFIAAEAgPEMWwaQBhAAAMCw/o8hYAAAANOQAAIAABgWAZIAAgAAGIYEEAAAGI9lYAAAAODRSAABAIDxTFsGhgQQAADAMCSAAADAeIYFgDSAAAAApnWADAEDAAAYhgQQAAAYj2VgAAAA4NFIAAEAgPFYBgYAAAAejQQQAAAYz7AAkAQQAADANCSAAAAAhkWANIAAAMB4LAMDAAAAj0YCCAAAjMcyMAAAAPBoJIAAAMB4hgWAJIAAAACmIQEEAAAwLAIkAQQAADAMCSAAADAe6wACAADAo9EAAgAA49ls7ttKY9KkSbLZbC5bkyZNyvzzMgQMAACMV5EGgJs3b64vv/yy+HWlSmXfrtEAAgAAVCCVKlVSRESEW+/BEDAAAIDNfZvD4VBWVpbL5nA4zlnK7t27VatWLTVo0EC33367Dhw4UOYflwYQAADAjRITExUYGOiyJSYmnvXcDh06aM6cOVq2bJlmzZqlffv2qXPnzjp58mSZ1mRzOp3OMr1iBZCVV2R1CShHPpX47xjAU72b8ovVJaAcDWlfx7J77zh0ym3Xrh/sfUbiZ7fbZbfbz/veEydOKDIyUlOnTtXw4cPLrCbmAAIAALhRSZu9swkKClLjxo2VmppapjURnQAAAONVlGVg/io7O1t79uxRzZo1y+aD/h8aQAAAgApi7NixWrNmjfbv369vvvlGN998s7y9vXXbbbeV6X0YAgYAAMarKOsA/vrrr7rtttuUkZGhGjVq6KqrrtL69etVo0aNMr0PDSAAAEAF6QDfeeedcrkPQ8AAAACGIQEEAADGs1WUCLCckAACAAAYhgQQAAAY758u13KxIQEEAAAwDAkgAAAwnmEBIAkgAACAaWgAL3Lfb9qoMaNHqnePLrq8dVOtXvWl1SWhHLyzcIF6X/MvXd62pW4fdIu2bN5sdUlwI75vz3Rg+2YteuFxvRR7q56+vYd2fve1y/EdG7/SwsTxmnrvzXr69h5K21+2vwWLv7C5cauAaAAvcrm5uWocFaVH4idYXQrKybLPP9MLzyXq3vtj9c57ixUV1UQj7x2ujIwMq0uDG/B9e658R57C6zZQr6Gjz3q8IC9PdaJaqPugEeVcmZlsbvxfRcQcwItcp6u6qNNVXawuA+Vo3twk9RswUH1v7i9JenxigtauXa0lH36g4SPusbg6lDW+b8/VqM0VatTminMeb9n5GknSiSNp5VUSDEICCFxECvLztf2nbboyumPxPi8vL115ZUdt/vEHCyuDO/B9A+XHZnPfVhFZ3gBu375dSUlJ2rFjhyRpx44dGjlypO666y6tWrXqvO93OBzKyspy2RwOh7vLBixx/MRxFRYWKiQkxGV/SEiIjh49alFVcBe+bwDuYmkDuGzZMrVp00Zjx45V27ZttWzZMnXp0kWpqan6+eef1bNnz/M2gYmJiQoMDHTZpj4/pZw+AQAA8ASGPQNibQM4efJkjRs3ThkZGUpKStLgwYM1YsQIrVixQitXrtS4ceM0ZcrfN3Px8fHKzMx02eLGPVpOnwAoX9WDqsvb2/uMBwAyMjIUGhpqUVVwF75vAO5iaQO4bds2DR06VJI0cOBAnTx5UgMGDCg+fvvtt2vzeZY7sNvtCggIcNnsdrs7ywYsU9nHR02bNdeG9cnF+4qKirRhQ7JatW5rYWVwB75voBwZFgFa/hSw7f9mR3p5ecnX11eBgYHFx/z9/ZWZmWlVaReFU6dy9MuBA8WvD/72q3bu2K7AwEBF1KxlYWVwlztjhmnCY+PVvHkLtWjZSvPnzVVubq763tzP6tLgBnzfnis/L1fH0n4rfn3iyCGl7U+VXzV/BYaGKzc7S5lHDyv7xB8J8LFDv0iSqgUFq1pQsCU1w3NY2gDWq1dPu3fvVsOGDSVJycnJqlu3bvHxAwcOqGbNmlaVd1HYvm2b7rs7pvj1tBeelSRdf1NfTXoy0aqy4EbX9r5Ox48d08xXX9bRo0cU1aSpZr72hkIYEvRIfN+e69DenZr/9Nji11/Ony1JatW5p2687xHt2pSsT15/vvj44lefliR17nenuvSPEcpWRV2vz11sTqfTadXNZ8+erTp16uj6668/6/HHHntMhw8f1htvvFGq62blFZVFebhI+FSy/GF2AG7ybsovVpeAcjSkfR3L7n3gmPtWEKkbXPGmplnaALoLDaBZaAABz0UDaBYawPJj+RxAAAAAq5k1AFwBFoIGAABA+SIBBAAAxquoP9nmLiSAAAAAhiEBBAAAMGwWIAkgAACAYUgAAQCA8UybA0gDCAAAjGdY/8cQMAAAgGlIAAEAgPFMGwImAQQAADAMCSAAADCezbBZgCSAAAAAhiEBBAAAMCsAJAEEAAAwDQkgAAAwnmEBIA0gAAAAy8AAAADAo5EAAgAA47EMDAAAADwaCSAAAIBZASAJIAAAgGlIAAEAgPEMCwBJAAEAAExDAggAAIxn2jqANIAAAMB4LAMDAAAAj0YCCAAAjGfaEDAJIAAAgGFoAAEAAAxDAwgAAGAY5gACAADjMQcQAAAAHo0EEAAAGM+0dQBpAAEAgPEYAgYAAIBHIwEEAADGMywAJAEEAAAwDQkgAACAYREgCSAAAIBhSAABAIDxTFsGhgQQAADAMCSAAADAeKwDCAAAAI9GAggAAIxnWABIAwgAAGBaB8gQMAAAgGFoAAEAgPFsbvzfhZgxY4bq1asnX19fdejQQd9++22Zfl4aQAAAgApk0aJFiouL08SJE/X999+rdevW6tWrlw4fPlxm96ABBAAAxrPZ3LeV1tSpUzVixAgNGzZMzZo10+zZs1WlShW99dZbZfZ5aQABAADcyOFwKCsry2VzOBxnPTc/P1+bNm1Sjx49ivd5eXmpR48eSk5OLrOaPPIp4ABf8/pah8OhxMRExcfHy263W10O3Izv2ywmf99D2texuoRyZ/L3bSVfN3ZEk55KVEJCgsu+iRMnatKkSWece/ToURUWFio8PNxlf3h4uHbs2FFmNdmcTqezzK4Gy2RlZSkwMFCZmZkKCAiwuhy4Gd+3Wfi+zcL37XkcDscZiZ/dbj9rg3/w4EFdcskl+uabbxQdHV28/5FHHtGaNWu0YcOGMqnJIxNAAACAiuJczd7ZhIaGytvbW+np6S7709PTFRERUWY1mTdWCgAAUEH5+PioXbt2WrlyZfG+oqIirVy50iUR/KdIAAEAACqQuLg4xcTEqH379rriiis0ffp05eTkaNiwYWV2DxpAD2G32zVx4kQmDBuC79ssfN9m4fvGrbfeqiNHjuiJJ55QWlqa2rRpo2XLlp3xYMg/wUMgAAAAhmEOIAAAgGFoAAEAAAxDAwgAAGAYGkAAAADD0AB6iBkzZqhevXry9fVVhw4d9O2331pdEtxg7dq1uvHGG1WrVi3ZbDYtWbLE6pLgRomJibr88svl7++vsLAw9e3bVzt37rS6LLjJrFmz1KpVKwUEBCggIEDR0dH6/PPPrS4LHooG0AMsWrRIcXFxmjhxor7//nu1bt1avXr10uHDh60uDWUsJydHrVu31owZM6wuBeVgzZo1io2N1fr167VixQoVFBSoZ8+eysnJsbo0uEHt2rU1ZcoUbdq0Sd99953+9a9/qU+fPtq2bZvVpcEDsQyMB+jQoYMuv/xyvfrqq5L+WDG8Tp06Gj16tB599FGLq4O72Gw2LV68WH379rW6FJSTI0eOKCwsTGvWrFGXLl2sLgflIDg4WM8//7yGDx9udSnwMCSAF7n8/Hxt2rRJPXr0KN7n5eWlHj16KDk52cLKAJS1zMxMSX80BfBshYWFeuedd5STk1OmP/8FnMYvgVzkjh49qsLCwjNWBw8PD9eOHTssqgpAWSsqKtJDDz2kTp06qUWLFlaXAzfZsmWLoqOjlZeXp2rVqmnx4sVq1qyZ1WXBA9EAAsBFIDY2Vlu3btW6deusLgVuFBUVpZSUFGVmZur9999XTEyM1qxZQxOIMkcDeJELDQ2Vt7e30tPTXfanp6crIiLCoqoAlKVRo0bpk08+0dq1a1W7dm2ry4Eb+fj4qFGjRpKkdu3aaePGjXrppZf02muvWVwZPA1zAC9yPj4+ateunVauXFm8r6ioSCtXrmTeCHCRczqdGjVqlBYvXqxVq1apfv36VpeEclZUVCSHw2F1GfBAJIAeIC4uTjExMWrfvr2uuOIKTZ8+XTk5ORo2bJjVpaGMZWdnKzU1tfj1vn37lJKSouDgYNWtW9fCyuAOsbGxWrhwoZYuXSp/f3+lpaVJkgIDA+Xn52dxdShr8fHx6t27t+rWrauTJ09q4cKFWr16tZYvX251afBALAPjIV599VU9//zzSktLU5s2bfTyyy+rQ4cOVpeFMrZ69Wp17979jP0xMTGaM2dO+RcEt7LZbGfdn5SUpKFDh5ZvMXC74cOHa+XKlTp06JACAwPVqlUrjR8/Xtdcc43VpcED0QACAAAYhjmAAAAAhqEBBAAAMAwNIAAAgGFoAAEAAAxDAwgAAGAYGkAAAADD0AACAAAYhgYQAADAMDSAACqsoUOHqm/fvsWvu3Xrpoceeqjc61i9erVsNptOnDhR7vcGAHegAQRQakOHDpXNZpPNZpOPj48aNWqkyZMn6/fff3frfT/88EM9+eSTJTqXpg0Azq2S1QUAuDhde+21SkpKksPh0GeffabY2FhVrlxZ8fHxLufl5+fLx8enTO4ZHBxcJtcBANORAAK4IHa7XREREYqMjNTIkSPVo0cPffTRR8XDtk8//bRq1aqlqKgoSdIvv/yigQMHKigoSMHBwerTp4/2799ffL3CwkLFxcUpKChIISEheuSRR/TXnyr/6xCww+HQ+PHjVadOHdntdjVq1Ehvvvmm9u/fr+7du0uSqlevLpvNpqFDh0qSioqKlJiYqPr168vPz0+tW7fW+++/73Kfzz77TI0bN5afn5+6d+/uUicAeAIaQABlws/PT/n5+ZKklStXaufOnVqxYoU++eQTFRQUqFevXvL399dXX32lr7/+WtWqVdO1115b/J4XX3xRc+bM0VtvvaV169bp2LFjWrx48d/ec8iQIfrvf/+rl19+Wdu3b9drr72matWqqU6dOvrggw8kSTt37tShQ4f00ksvSZISExP19ttva/bs2dq2bZvGjBmjO+64Q2vWrJH0R6Par18/3XjjjUpJSdHdd9+tRx991F1/NgCwBEPAAP4Rp9OplStXavny5Ro9erSOHDmiqlWr6o033ige+p0/f76Kior0xhtvyGazSZKSkpIUFBSk1atXq2fPnpo+fbri4+PVr18/SdLs2bO1fPnyc953165devfdd7VixQr16NFDktSgQYPi46eHi8PCwhQUFCTpj8TwmWee0Zdffqno6Oji96xbt06vvfaaunbtqlmzZqlhw4Z68cUXJUlRUVHasmWLnn322TL8qwGAtWgAAVyQTz75RNWqVVNBQYGKioo0ePBgTZo0SbGxsWrZsqXLvL8ff/xRqamp8vf3d7lGXl6e9uzZo8zMTB06dEgdOnQoPlapUiW1b9/+jGHg01JSUuTt7a2uXbuWuObU1FSdOnVK11xzjcv+/Px8tW3bVpK0fft2lzokFTeLAOApaAABXJDu3btr1qxZ8vHxUa1atVSp0v//10nVqlVdzs3Ozla7du20YMGCM65To0aNC7q/n59fqd+TnZ0tSfr00091ySWXuByz2+0XVAcAXIxoAAFckKpVq6pRo0YlOveyyy7TokWLFBYWpoCAgLOeU7NmTW3YsEFdunSRJP3+++/atGmTLrvssrOe37JlSxUVFWnNmjXFQ8B/djqBLCwsLN7XrFkz2e12HThw4JzJYdOmTfXRRx+57Fu/fv35PyQAXER4CASA291+++0KDQ1Vnz599NVXX2nfvn1avXq1HnjgAf3666+SpAcffFBTpkzRkiVLtGPHDt1///1/u4ZfvXr1FBMTo7vuuktLliwpvua7774rSYqMjJTNZtMnn3yiI0eOKDs7W/7+/ho7dqzGjBmjuXPnas+ePfr+++/1yiuvaO7cuZKk++67T7t379a4ceO0c+dOLVy4UHPmzHH3nwgAyhUNIAC3q1KlitauXau6deuqX79+atq0qYYPH668vLziRPDhhx/WnXfeqZiYGEVHR8vf318333zz31531qxZGjBggO6//341adJEI0aMUE5OjiTpkksuUUJCgh599FGFh4dr1KhRkqQnn3xSEyZMUGJiopo2baprr71Wn376qerXry9Jqlu3rj744AMtWbJErVu31uzZs/XMM8+48a8DAOXP5jzXDGsAAAB4JBJAAAAAw9AAAgAAGIYGEAAAwDA0gAAAAIahAQQAADAMDSAAAIBhaAABAAAMQwMIAABgGBpAAAAAw9AAAgAAGIYGEAAAwDD/D0gmHRqqgtCDAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}